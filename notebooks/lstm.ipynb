{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0ad4b3",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "In this notebook the LSTM model will be implemented. We will use historical energy consumption data and meteorological data to make a prediction on future consumption values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9c6fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "seed=99\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "612307ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "# Check for TensorFlow GPU access\n",
    "print(tf.config.list_physical_devices())\n",
    "# See TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4755f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "morocco = pd.read_csv(\"../data/processed/morocco_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf5c1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "morocco = pd.read_csv(\"../data/processed/morocco_processed.csv\")\n",
    "usa = pd.read_csv(\"../data/raw/usa.csv\")\n",
    "paraguay = pd.read_csv(\"../data/raw/paraguay.csv\")\n",
    "#spain_cities_average = pd.read_csv('spain_cities_average.csv')\n",
    "#barcelona = pd.read_csv('spain_cities_barcelona.csv')\n",
    "#bilbao = pd.read_csv('spain_cities_bilbao.csv')\n",
    "#madrid = pd.read_csv('spain_cities_madrid.csv')\n",
    "#seville = pd.read_csv('spain_cities_seville.csv')\n",
    "#valencia = pd.read_csv('spain_cities_valencia.csv')\n",
    "#spain_houses = pd.read_csv('spain_houses.csv')\n",
    "\n",
    "# remove missing data from end of datasets since we cant linear interpolate it\n",
    "usa = usa.iloc[:-18]\n",
    "paraguay = paraguay.iloc[:-360]\n",
    "datasets = {'morocco': morocco, 'paraguay': paraguay, 'usa': usa}\n",
    "datasets_electricity = {'morocco': morocco, 'paraguay': paraguay, 'usa': usa}\n",
    "\n",
    "# convert DateTime column to datetime\n",
    "for dataset in datasets:\n",
    "    if dataset in ['spain_cities_average', 'barcelona', 'bilbao', 'madrid', 'seville', 'valencia', 'spain_houses']:\n",
    "        datasets[dataset]['DateTime'] = pd.to_datetime(datasets[dataset]['DateTime'], utc=True)\n",
    "    else:\n",
    "        datasets[dataset]['DateTime'] = pd.to_datetime(datasets[dataset]['DateTime'])\n",
    "\n",
    "# Consumption will never be zero, so mark that as missing data\n",
    "for dataset_name in datasets:\n",
    "    datasets[dataset_name].loc[datasets[dataset_name]['Consumption'] == 0, 'Consumption'] = np.nan\n",
    "\n",
    "# Something is wrong with the \"Spain houses\" data, so set consumption values above 2000 to missing\n",
    "#datasets['spain_houses'].loc[datasets['spain_houses']['Consumption'] > 2000, 'Consumption'] = np.nan\n",
    "\n",
    "#print(spain_houses.describe())\n",
    "# Fill missing data with simple linear interpolation\n",
    "for dataset_name in datasets:\n",
    "    datasets[dataset_name][[\"Consumption\", \"Temperature\"]] = datasets[dataset_name][[\"Consumption\", \"Temperature\"]].interpolate(method='cubic')\n",
    "\n",
    "#print(spain_houses.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47d82c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morocco\n",
      "DateTime                 0\n",
      "Consumption              0\n",
      "Temperature              0\n",
      "Humidity                 0\n",
      "Wind Speed               0\n",
      "general diffuse flows    0\n",
      "diffuse flows            0\n",
      "dtype: int64\n",
      "\n",
      "paraguay\n",
      "DateTime       0\n",
      "Consumption    0\n",
      "Temperature    0\n",
      "dtype: int64\n",
      "\n",
      "usa\n",
      "DateTime       0\n",
      "Consumption    0\n",
      "Temperature    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets_electricity:\n",
    "    dataset = datasets[dataset_name]\n",
    "    print(dataset_name)\n",
    "    print(dataset.isna().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11931c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature functions\n",
    "# augment_time_series\n",
    "# add_time_features\n",
    "# add_lagged_timesteps\n",
    "# add_target_without_cyclicality\n",
    "# add_moving_mean\n",
    "# upsample_timeseries\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "def add_lagged_timesteps(input_df, lag_periods=[1,2,3,24], lagged_feature='Consumption'):\n",
    "    # Add lagged timesteps of a feature\n",
    "    df = input_df.copy()\n",
    "    for lag_period in lag_periods:\n",
    "        df['lagged_' + lagged_feature + \"_\" + str(lag_period)] = df[lagged_feature].shift(lag_period)\n",
    "    return df\n",
    "\n",
    "def add_time_features(input_df):\n",
    "    # Sin and cos encoding of time features\n",
    "    df = input_df.copy()\n",
    "    df['hour_of_day_sin'] = np.sin(2 * np.pi * df['DateTime'].dt.hour / 24)\n",
    "    df['hour_of_day_cos'] = np.cos(2 * np.pi * df['DateTime'].dt.hour / 24)\n",
    "\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['DateTime'].dt.dayofweek / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['DateTime'].dt.dayofweek / 7)\n",
    "\n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['DateTime'].dt.dayofyear / 365)\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['DateTime'].dt.dayofyear / 365)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c753e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add autocorrelation of steps: add lagged features, ridge regression fitting and evaluation\n",
    "# MAPE for different lookback horizons with Ridge Regression: Not much difference between 48, 168, 336\n",
    "# MAPE for different hyperparameters with Ridge Regression: no difference for alpha values\n",
    "# MAPE for different features with Ridge Regression:\n",
    "# - almost no diff between 48 steps and lag temp+ time encoding\n",
    "# - almost no diff 48 steps, target without cyclicality, moving mean feature, granger causality feature, added data augmentation\n",
    "\n",
    "# MAPE for different hyperparameters with LGBM: more difference, but not enough for me to care: estimators, leaves\n",
    "# MAPE of LGBMRegressor with different hyperparameters predicting Consumption: same as above\n",
    "# MAPE for weather features with LGBM: no diff between 48-steps and lagged temp + time encoding\n",
    "# MAPE for different lookback horizons with LGBM: no diff 48, 169, 336\n",
    "# MAPE of different features predicting Consumption with LGBRegressor: not much diff\n",
    "# MAPE for different features with LGBM: not that much\n",
    "\n",
    "# MAPE for different hyperparameters with LSTM: lookback [6, 12, 24], layers [1,2].\n",
    "# - They generally performed the same. 24 hrs 2 layers did worst for spain houses and usa dataset. I should test this\n",
    "\n",
    "# BiLSTM\n",
    "\n",
    "# Transformer v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf668fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#morocco.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ec2cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumption</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>general diffuse flows</th>\n",
       "      <th>diffuse flows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>398860.62358</td>\n",
       "      <td>6.196833</td>\n",
       "      <td>75.066667</td>\n",
       "      <td>0.081833</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.098833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>346671.15726</td>\n",
       "      <td>5.548833</td>\n",
       "      <td>77.583333</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>312539.28984</td>\n",
       "      <td>5.054333</td>\n",
       "      <td>78.933333</td>\n",
       "      <td>0.082333</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.129167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>293486.68529</td>\n",
       "      <td>5.004333</td>\n",
       "      <td>77.083333</td>\n",
       "      <td>0.082833</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>0.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>286287.83008</td>\n",
       "      <td>5.097667</td>\n",
       "      <td>74.050000</td>\n",
       "      <td>0.082333</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.122833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Consumption  Temperature   Humidity  Wind Speed  \\\n",
       "DateTime                                                                \n",
       "2017-01-01 00:00:00  398860.62358     6.196833  75.066667    0.081833   \n",
       "2017-01-01 01:00:00  346671.15726     5.548833  77.583333    0.082000   \n",
       "2017-01-01 02:00:00  312539.28984     5.054333  78.933333    0.082333   \n",
       "2017-01-01 03:00:00  293486.68529     5.004333  77.083333    0.082833   \n",
       "2017-01-01 04:00:00  286287.83008     5.097667  74.050000    0.082333   \n",
       "\n",
       "                     general diffuse flows  diffuse flows  \n",
       "DateTime                                                   \n",
       "2017-01-01 00:00:00               0.063500       0.098833  \n",
       "2017-01-01 01:00:00               0.056833       0.112500  \n",
       "2017-01-01 02:00:00               0.063000       0.129167  \n",
       "2017-01-01 03:00:00               0.059833       0.141000  \n",
       "2017-01-01 04:00:00               0.058000       0.122833  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null values: 0\n",
      "\n",
      "data types: Consumption              float64\n",
      "Temperature              float64\n",
      "Humidity                 float64\n",
      "Wind Speed               float64\n",
      "general diffuse flows    float64\n",
      "diffuse flows            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "display(morocco.head())\n",
    "print('null values:', morocco.isnull().sum().sum())\n",
    "print()\n",
    "print('data types:', morocco.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a86caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature importances\n",
    "for i, dataset_name in enumerate(datasets_electricity):\n",
    "    print(f\"\\nFeature importances for {dataset_name}:\")\n",
    "    for feature, importance in feature_importances_list[i][:7]:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553e41e",
   "metadata": {},
   "source": [
    "### Literature review\n",
    "In the previous thesis written by Andreas:  \n",
    "* Scikit StandardScaler\n",
    "* 48h lookback horizon\n",
    "* Hyperparameter tuning on lookback horizon and number of layers using grid search.\n",
    "* The parameters to adjust was selected so that the training would use less than 12h on a NVIDIA P100 graphics card.\n",
    "* Did not use cross-validation given time series data. Instead used train-test split using the last 90 days for test. This makes sense, and is kinda how I selected my data.\n",
    "* Batch size 32, max 150 epochs, learning rate schedulers on plateau, initial lr=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b599435",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n",
    "The Morocco dataset contains one year of data of 10 min granularity. In order to respect the temporal order of observations we'll split on a given timestep and use the data before the respective timestamp as training data and the data after will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd97652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    split_date = pd.Timestamp('2017-12-01')\n",
    "\n",
    "    train = morocco[(morocco['month'] < 12)]\n",
    "    test = morocco[(morocco['month'] >= 12)]\n",
    "\n",
    "    X_train = train.drop(columns=['Consumption'])\n",
    "    y_train = train['Consumption']\n",
    "\n",
    "    X_test = test.drop(columns=['Consumption'])\n",
    "    y_test = test['Consumption']\n",
    "    \n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460d0d7",
   "metadata": {},
   "source": [
    "### Tensorflow implementation\n",
    "You should have your data split into input sequences (X) and the corresponding labels (y). Here, X is expected to be a 3D array of shape (number of samples, time steps, features per step), and y is a 2D array of shape (number of samples, target variable).\n",
    "\n",
    "Replace 50 with the number of LSTM units you want. The input_shape parameter should match the shape of your input data, excluding the sample dimension (e.g., (time steps, features per step)).\n",
    "\n",
    "Here, X.shape[1] is the number of time steps, and X.shape[2] is the number of features per time step. Adjust the epochs and validation_split as necessary.\n",
    "\n",
    "Assuming X_test is your test dataset prepared in the same way as your training dataset (X).\n",
    "\n",
    "Remember, the effectiveness of your model heavily depends on the quality of your data, the way you've preprocessed it, and the hyperparameters of the model. It's often beneficial to experiment with different configurations, LSTM layers, and maybe adding dropout layers to improve the model's performance and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f2b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94069cd0",
   "metadata": {},
   "source": [
    "The LSTM model is defined with input_shape=(n_steps, n_features), which expects 3-dimensional input. Cannot directly pass X_train and y_train to the models fit() function without reshaping them to include the time steps dimension. You need to reshape your `X_train` and `X_test` data into the 3-dimensional shape expected by the LSTM layers. This is typically done by segmenting your time series data into sequences.  \n",
    "\n",
    "Tensorflow introduces TimeseriesGenerator, which automatically handle the segmentation of time series data into (samples, time steps, features) format that LSTM layers expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseriesgenerator is deprecated. Here is the manual code.\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "n_steps = lookback  # time steps parameter\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled.flatten(), n_steps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled.flatten(), n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b5b8a",
   "metadata": {},
   "source": [
    "Selecting the window size/ n_steps. Pick one that allows the model to learn long-term dependencies, but hyptuning isn't neccessary. We perform short term forecasting, so we will use 2 days = 48 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3dafaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler, adjusting the learning rate based on the epoch number\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    elif epoch%10==0:\n",
    "        return lr * tf.math.exp(-0.3)\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "# Defines the LSTM model\n",
    "def lstm_model(train_generator, test_generator, n_steps, n_features, n_epochs, n_layers):\n",
    "    model = Sequential()\n",
    "    for _ in range(n_layers - 1):\n",
    "        model.add(LSTM(\n",
    "            # LSTM units = 32\n",
    "            # input shape = (X.shape[1], X.shape[2])\n",
    "            32, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)\n",
    "    ))\n",
    "    \n",
    "    model.add(LSTM(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate = 0.001), loss='mse')\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)]\n",
    "    \n",
    "    #model.fit(X, y, epochs=20, validation_split=0.2, verbose=1)\n",
    "    model.fit(train_generator, epochs=n_epochs, verbose=0, validation_data=test_generator)#, callbacks=callbacks)\n",
    "    #model.fit(X_train, y_train, epochs=n_epochs, verbose=1, callbacks=callbacks)\n",
    "    return model\n",
    "\n",
    "def lstm_fitting_and_evaluation(features, target, dataset_name, model_file_identifier='_', lookback = 6, n_layers = 2):\n",
    "    # split_and_scale: Test set is the last 90 days\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=2160, random_state=seed, shuffle=False)\n",
    "    \n",
    "    # Scale X data\n",
    "    XScaler = StandardScaler()\n",
    "    XScaler.fit(X_train)\n",
    "    scaled_X_train = XScaler.transform(X_train)\n",
    "    scaled_X_test = XScaler.transform(X_test)\n",
    "\n",
    "    # Scale Y data\n",
    "    YScaler = StandardScaler()\n",
    "    YScaler.fit(y_train.values.reshape(-1, 1))\n",
    "    scaled_y_train = YScaler.transform(y_train.values.reshape(-1, 1))\n",
    "    scaled_y_test = YScaler.transform(y_test.values.reshape(-1, 1))\n",
    "    \n",
    "    # Variables\n",
    "    n_steps = lookback # Hours to look back\n",
    "    batch = 64\n",
    "    epochs = 150\n",
    "    \n",
    "    # Generate sequences to learn on\n",
    "    generator_train = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=n_steps, batch_size=batch)\n",
    "    generator_test = TimeseriesGenerator(scaled_X_test, scaled_y_test, length=n_steps, batch_size=batch)\n",
    "    \n",
    "    \n",
    "    model_file_path = \"lstm/\" + model_file_identifier + \"/\" + dataset_name\n",
    "    try: # Try to load the model if it already exists\n",
    "        model = tf.keras.models.load_model(model_file_path)\n",
    "    except: # If it doesn't exist, train the model and save it\n",
    "        n_features = X_train.shape[1]\n",
    "        #model = create_lstm_model(X_train, X_test, y_train, y_test, n_steps, n_features, epochs, n_layers)\n",
    "        model = lstm_model(generator_train, generator_test, n_steps, n_features, epochs, n_layers)\n",
    "        #model.save(model_file_path)\n",
    "        #tf.saved_model.save()\n",
    "    \n",
    "    # evaluate the model on the test set\n",
    "    y_pred_scaled = model.predict(generator_test)\n",
    "    y_pred = YScaler.inverse_transform(y_pred_scaled)\n",
    "    mape = mean_absolute_percentage_error(y_test[n_steps:], y_pred)\n",
    "    mae = mean_absolute_error(y_test[n_steps:], y_pred)\n",
    "    r2 = r2_score(y_test[n_steps:], y_pred)\n",
    "    print(f'{dataset_name}, MAE: {mae:.2f}, MAPE: {mape:.3f}, R2: {r2:.3f}')\n",
    "    \n",
    "    # Calculate aic and bic values\n",
    "    # Compute AIC and BIC for SVM model\n",
    "    n = len(y_test)\n",
    "    k = X_train.shape[1] + 1  # Number of parameters including intercept\n",
    "    log_likelihood = -0.5 * n * np.log(2 * np.pi * mae) - n * np.log(mae)  # Assuming normal distribution for errors\n",
    "    aic_value = 2 * k - 2 * log_likelihood\n",
    "    bic_value = np.log(n) * k - 2 * log_likelihood\n",
    "    print(f'LSTM Model - AIC: {aic_value:.2f}, BIC: {bic_value:.2f}')\n",
    "\n",
    "    return r2, mae, mape, aic_value, bic_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lstm_fitting_and_evaluation(data.drop(columns=['DateTime', 'Consumption', 'Temperature']), data['Consumption'], dataset_name, model_file_identifier=str(lookback) + \"_\" + str(n_layers), lookback=lookback, n_layers=n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4084f",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "The results from Andreas confused me, so test it out.\n",
    "\n",
    "[ ] MAPE for different hyperparameters with LSTM: different lookback horizons and layers  \n",
    "[ ] MAPE for weather features with LSTM  \n",
    "[ ] MAPE for different features with LSTM (baseline, some other stuff)  \n",
    "[ ] MAPE for different lookback horizons with LSTM (48, 168, 336)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39acfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: lookback=6, n_layers=1\n",
      "Epoch 1/150\n",
      "\u001b[1m 74/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0961  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9043 - val_loss: 0.0613\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0611 - val_loss: 0.0495\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0474 - val_loss: 0.0489\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - val_loss: 0.0294\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0298 - val_loss: 0.0296\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0284 - val_loss: 0.0229\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - val_loss: 0.0235\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - val_loss: 0.0217\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0800 - val_loss: 0.0176\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0202 - val_loss: 0.0175\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 0.0144\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0140\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0130\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0222\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0137\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - val_loss: 0.0120\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - val_loss: 0.0120\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0194 - val_loss: 0.0140\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0108\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0102\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0206\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0133\n",
      "Epoch 52/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0098\n",
      "Epoch 53/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 54/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 55/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 56/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 57/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 58/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 59/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0126\n",
      "Epoch 60/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 61/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 62/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 63/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 64/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0162\n",
      "Epoch 65/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 66/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 67/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 69/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 70/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 71/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 72/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 73/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 74/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 75/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0107\n",
      "Epoch 76/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 77/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 78/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 79/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 80/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 81/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 82/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 83/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 84/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - val_loss: 0.0094\n",
      "Epoch 85/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 86/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 87/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 88/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 89/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 90/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0109\n",
      "Epoch 91/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - val_loss: 0.0090\n",
      "Epoch 92/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 93/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 94/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0093\n",
      "Epoch 95/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - val_loss: 0.0087\n",
      "Epoch 96/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0097\n",
      "Epoch 97/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 98/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 99/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 100/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 101/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 102/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - val_loss: 0.0097\n",
      "Epoch 103/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 104/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 105/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 106/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0130\n",
      "Epoch 107/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 108/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 109/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0109\n",
      "Epoch 110/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 111/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0121\n",
      "Epoch 112/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 113/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 114/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 115/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - val_loss: 0.0151\n",
      "Epoch 116/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 117/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - val_loss: 0.0089\n",
      "Epoch 118/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0118\n",
      "Epoch 119/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 120/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - val_loss: 0.0086\n",
      "Epoch 121/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 122/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 123/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 124/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 125/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0210\n",
      "Epoch 126/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 127/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0083\n",
      "Epoch 128/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - val_loss: 0.0096\n",
      "Epoch 129/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 130/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - val_loss: 0.0096\n",
      "Epoch 131/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - val_loss: 0.0113\n",
      "Epoch 132/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 133/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0114\n",
      "Epoch 134/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - val_loss: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 136/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 137/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 138/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 139/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 140/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - val_loss: 0.0092\n",
      "Epoch 141/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0114\n",
      "Epoch 142/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0087\n",
      "Epoch 143/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0102\n",
      "Epoch 144/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - val_loss: 0.0119\n",
      "Epoch 145/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 146/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 147/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 148/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - val_loss: 0.0088\n",
      "Epoch 149/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - val_loss: 0.0083\n",
      "Epoch 150/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0112\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "morocco, MAE: 8027.25, MAPE: 0.022, R2: 0.982\n",
      "SVM Model - AIC: 62334.89, BIC: 62635.81\n",
      "Epoch 1/150\n",
      "\u001b[1m120/508\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5688  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3014 - val_loss: 0.0802\n",
      "Epoch 2/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0717 - val_loss: 0.0620\n",
      "Epoch 3/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0617 - val_loss: 0.0485\n",
      "Epoch 4/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0436 - val_loss: 0.0429\n",
      "Epoch 5/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0394 - val_loss: 0.0383\n",
      "Epoch 6/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0362 - val_loss: 0.0364\n",
      "Epoch 7/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0395 - val_loss: 0.0354\n",
      "Epoch 8/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0347 - val_loss: 0.0334\n",
      "Epoch 9/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0292 - val_loss: 0.0321\n",
      "Epoch 10/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0361 - val_loss: 0.0347\n",
      "Epoch 11/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0316 - val_loss: 0.0425\n",
      "Epoch 12/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0319 - val_loss: 0.0347\n",
      "Epoch 13/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0301 - val_loss: 0.0340\n",
      "Epoch 14/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0304 - val_loss: 0.0331\n",
      "Epoch 15/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0283 - val_loss: 0.0411\n",
      "Epoch 16/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0295 - val_loss: 0.0352\n",
      "Epoch 17/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0298 - val_loss: 0.0316\n",
      "Epoch 18/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0285 - val_loss: 0.0325\n",
      "Epoch 19/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0286 - val_loss: 0.0328\n",
      "Epoch 20/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0284 - val_loss: 0.0314\n",
      "Epoch 21/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0273 - val_loss: 0.0329\n",
      "Epoch 22/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0272 - val_loss: 0.0304\n",
      "Epoch 23/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0254 - val_loss: 0.0358\n",
      "Epoch 24/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0261 - val_loss: 0.0311\n",
      "Epoch 25/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0254 - val_loss: 0.0328\n",
      "Epoch 26/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0276 - val_loss: 0.0306\n",
      "Epoch 27/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0274 - val_loss: 0.0355\n",
      "Epoch 28/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0260 - val_loss: 0.0308\n",
      "Epoch 29/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0250 - val_loss: 0.0306\n",
      "Epoch 30/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0241 - val_loss: 0.0321\n",
      "Epoch 31/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0236 - val_loss: 0.0298\n",
      "Epoch 32/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0231 - val_loss: 0.0312\n",
      "Epoch 33/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0237 - val_loss: 0.0302\n",
      "Epoch 34/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0235 - val_loss: 0.0298\n",
      "Epoch 35/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0234 - val_loss: 0.0313\n",
      "Epoch 36/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0238 - val_loss: 0.0307\n",
      "Epoch 37/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0241 - val_loss: 0.0288\n",
      "Epoch 38/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0243 - val_loss: 0.0292\n",
      "Epoch 39/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0230 - val_loss: 0.0292\n",
      "Epoch 40/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0220 - val_loss: 0.0297\n",
      "Epoch 41/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0219 - val_loss: 0.0357\n",
      "Epoch 42/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0301 - val_loss: 0.0316\n",
      "Epoch 43/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0228 - val_loss: 0.0285\n",
      "Epoch 44/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0217 - val_loss: 0.0325\n",
      "Epoch 45/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0222 - val_loss: 0.0283\n",
      "Epoch 46/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0210 - val_loss: 0.0295\n",
      "Epoch 47/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0207 - val_loss: 0.0290\n",
      "Epoch 48/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0225 - val_loss: 0.0290\n",
      "Epoch 49/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0212 - val_loss: 0.0286\n",
      "Epoch 50/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0208 - val_loss: 0.0306\n",
      "Epoch 51/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0216 - val_loss: 0.0279\n",
      "Epoch 52/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0195 - val_loss: 0.0290\n",
      "Epoch 53/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0212 - val_loss: 0.0290\n",
      "Epoch 54/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0220 - val_loss: 0.0304\n",
      "Epoch 55/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0213 - val_loss: 0.0281\n",
      "Epoch 56/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0207 - val_loss: 0.0287\n",
      "Epoch 57/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0217 - val_loss: 0.0283\n",
      "Epoch 58/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0296\n",
      "Epoch 59/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0205 - val_loss: 0.0288\n",
      "Epoch 60/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0301\n",
      "Epoch 61/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0209 - val_loss: 0.0348\n",
      "Epoch 62/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0210 - val_loss: 0.0278\n",
      "Epoch 63/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0201 - val_loss: 0.0300\n",
      "Epoch 64/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0201 - val_loss: 0.0289\n",
      "Epoch 65/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0200 - val_loss: 0.0301\n",
      "Epoch 66/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0198 - val_loss: 0.0291\n",
      "Epoch 67/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0293\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0195 - val_loss: 0.0295\n",
      "Epoch 69/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0197 - val_loss: 0.0284\n",
      "Epoch 70/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0194 - val_loss: 0.0292\n",
      "Epoch 71/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0302\n",
      "Epoch 72/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0196 - val_loss: 0.0295\n",
      "Epoch 73/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0197 - val_loss: 0.0303\n",
      "Epoch 74/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0284\n",
      "Epoch 75/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0295\n",
      "Epoch 76/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0195 - val_loss: 0.0331\n",
      "Epoch 77/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0196 - val_loss: 0.0286\n",
      "Epoch 78/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0291\n",
      "Epoch 79/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0286\n",
      "Epoch 80/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0191 - val_loss: 0.0283\n",
      "Epoch 81/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0191 - val_loss: 0.0294\n",
      "Epoch 82/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0296\n",
      "Epoch 83/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0180 - val_loss: 0.0302\n",
      "Epoch 84/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0304\n",
      "Epoch 85/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0184 - val_loss: 0.0282\n",
      "Epoch 86/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0186 - val_loss: 0.0291\n",
      "Epoch 87/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0302\n",
      "Epoch 88/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0198 - val_loss: 0.0298\n",
      "Epoch 89/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0176 - val_loss: 0.0306\n",
      "Epoch 90/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 0.0297\n",
      "Epoch 91/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0285\n",
      "Epoch 92/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0181 - val_loss: 0.0286\n",
      "Epoch 93/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0295\n",
      "Epoch 94/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0185 - val_loss: 0.0286\n",
      "Epoch 95/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0176 - val_loss: 0.0293\n",
      "Epoch 96/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0321\n",
      "Epoch 97/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0294\n",
      "Epoch 98/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0303\n",
      "Epoch 99/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0298\n",
      "Epoch 100/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0175 - val_loss: 0.0288\n",
      "Epoch 101/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0174 - val_loss: 0.0298\n",
      "Epoch 102/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0180 - val_loss: 0.0295\n",
      "Epoch 103/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0175 - val_loss: 0.0288\n",
      "Epoch 104/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0177 - val_loss: 0.0289\n",
      "Epoch 105/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0178 - val_loss: 0.0294\n",
      "Epoch 106/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0177 - val_loss: 0.0297\n",
      "Epoch 107/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0174 - val_loss: 0.0295\n",
      "Epoch 108/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0309\n",
      "Epoch 109/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0316\n",
      "Epoch 110/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0282\n",
      "Epoch 111/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0174 - val_loss: 0.0291\n",
      "Epoch 112/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0305\n",
      "Epoch 113/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0309\n",
      "Epoch 114/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0310\n",
      "Epoch 115/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0308\n",
      "Epoch 116/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0309\n",
      "Epoch 117/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0314\n",
      "Epoch 118/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165 - val_loss: 0.0309\n",
      "Epoch 119/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0319\n",
      "Epoch 120/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167 - val_loss: 0.0304\n",
      "Epoch 121/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0179 - val_loss: 0.0292\n",
      "Epoch 122/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165 - val_loss: 0.0303\n",
      "Epoch 123/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0308\n",
      "Epoch 124/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0296\n",
      "Epoch 125/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0164 - val_loss: 0.0308\n",
      "Epoch 126/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165 - val_loss: 0.0312\n",
      "Epoch 127/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0169 - val_loss: 0.0297\n",
      "Epoch 128/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0307\n",
      "Epoch 129/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0160 - val_loss: 0.0302\n",
      "Epoch 130/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165 - val_loss: 0.0303\n",
      "Epoch 131/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0306\n",
      "Epoch 132/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0160 - val_loss: 0.0306\n",
      "Epoch 133/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0166 - val_loss: 0.0315\n",
      "Epoch 134/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0164 - val_loss: 0.0303\n",
      "Epoch 136/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0159 - val_loss: 0.0309\n",
      "Epoch 137/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0297\n",
      "Epoch 138/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0159 - val_loss: 0.0298\n",
      "Epoch 139/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0175 - val_loss: 0.0314\n",
      "Epoch 140/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0159 - val_loss: 0.0313\n",
      "Epoch 141/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0155 - val_loss: 0.0313\n",
      "Epoch 142/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0308\n",
      "Epoch 143/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0155 - val_loss: 0.0303\n",
      "Epoch 144/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0313\n",
      "Epoch 145/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0157 - val_loss: 0.0297\n",
      "Epoch 146/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0159 - val_loss: 0.0308\n",
      "Epoch 147/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0303\n",
      "Epoch 148/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0310\n",
      "Epoch 149/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 0.0322\n",
      "Epoch 150/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0154 - val_loss: 0.0311\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "paraguay, MAE: 146.69, MAPE: 0.026, R2: 0.951\n",
      "SVM Model - AIC: 36392.15, BIC: 36670.37\n",
      "Epoch 1/150\n",
      "\u001b[1m111/582\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2214  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3345 - val_loss: 0.0578\n",
      "Epoch 2/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1969 - val_loss: 0.0476\n",
      "Epoch 3/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0643 - val_loss: 0.0384\n",
      "Epoch 4/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0488 - val_loss: 0.0439\n",
      "Epoch 5/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0409 - val_loss: 0.0282\n",
      "Epoch 6/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0656 - val_loss: 0.0322\n",
      "Epoch 7/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0416 - val_loss: 0.0240\n",
      "Epoch 8/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0420 - val_loss: 0.0282\n",
      "Epoch 9/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0563 - val_loss: 0.0283\n",
      "Epoch 10/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1692 - val_loss: 0.0262\n",
      "Epoch 11/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0894 - val_loss: 0.0434\n",
      "Epoch 12/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0565 - val_loss: 0.0224\n",
      "Epoch 13/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0869 - val_loss: 0.0984\n",
      "Epoch 14/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0610 - val_loss: 0.0206\n",
      "Epoch 15/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0252 - val_loss: 0.0212\n",
      "Epoch 16/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0410 - val_loss: 0.0200\n",
      "Epoch 17/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0251 - val_loss: 0.0264\n",
      "Epoch 18/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0457 - val_loss: 0.0195\n",
      "Epoch 19/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0321 - val_loss: 0.0184\n",
      "Epoch 20/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0323 - val_loss: 0.0176\n",
      "Epoch 21/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0226 - val_loss: 0.0171\n",
      "Epoch 22/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0416 - val_loss: 0.0169\n",
      "Epoch 23/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1547 - val_loss: 0.0206\n",
      "Epoch 24/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0258 - val_loss: 0.0174\n",
      "Epoch 25/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0203 - val_loss: 0.0170\n",
      "Epoch 26/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 0.0170\n",
      "Epoch 27/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0962 - val_loss: 0.0184\n",
      "Epoch 28/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0271 - val_loss: 0.0168\n",
      "Epoch 29/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 30/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0167\n",
      "Epoch 31/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0223 - val_loss: 0.0154\n",
      "Epoch 32/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0230 - val_loss: 0.0150\n",
      "Epoch 33/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0466 - val_loss: 0.0157\n",
      "Epoch 34/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0151\n",
      "Epoch 35/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 36/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0183 - val_loss: 0.0199\n",
      "Epoch 37/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0550 - val_loss: 0.0162\n",
      "Epoch 38/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1201 - val_loss: 0.0169\n",
      "Epoch 39/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0327 - val_loss: 0.0227\n",
      "Epoch 40/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0330 - val_loss: 0.0151\n",
      "Epoch 41/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0330 - val_loss: 0.0145\n",
      "Epoch 42/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0219 - val_loss: 0.0135\n",
      "Epoch 43/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0164 - val_loss: 0.0137\n",
      "Epoch 44/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 0.0132\n",
      "Epoch 45/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1478 - val_loss: 0.0230\n",
      "Epoch 46/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0220 - val_loss: 0.0160\n",
      "Epoch 47/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0173 - val_loss: 0.0136\n",
      "Epoch 48/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 49/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 50/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0199\n",
      "Epoch 51/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0260 - val_loss: 0.0211\n",
      "Epoch 52/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0336 - val_loss: 0.0143\n",
      "Epoch 53/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0151 - val_loss: 0.0259\n",
      "Epoch 54/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0288 - val_loss: 0.0139\n",
      "Epoch 55/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167 - val_loss: 0.0134\n",
      "Epoch 56/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 57/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0237 - val_loss: 0.0128\n",
      "Epoch 58/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0365 - val_loss: 0.0159\n",
      "Epoch 59/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2452 - val_loss: 0.0150\n",
      "Epoch 60/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0135\n",
      "Epoch 61/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167 - val_loss: 0.0140\n",
      "Epoch 62/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0145 - val_loss: 0.0129\n",
      "Epoch 63/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 64/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0229 - val_loss: 0.0176\n",
      "Epoch 65/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0651 - val_loss: 0.0155\n",
      "Epoch 66/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0198 - val_loss: 0.0136\n",
      "Epoch 67/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "Epoch 69/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 70/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0288 - val_loss: 0.0203\n",
      "Epoch 71/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0332 - val_loss: 0.0207\n",
      "Epoch 72/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0518 - val_loss: 0.0128\n",
      "Epoch 73/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0124\n",
      "Epoch 74/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0122\n",
      "Epoch 75/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 76/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 77/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 78/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0197 - val_loss: 0.0122\n",
      "Epoch 79/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0272 - val_loss: 0.0125\n",
      "Epoch 80/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0337 - val_loss: 0.0148\n",
      "Epoch 81/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0526 - val_loss: 0.0161\n",
      "Epoch 82/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0745 - val_loss: 0.0141\n",
      "Epoch 83/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 84/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 85/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 86/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0213 - val_loss: 0.0129\n",
      "Epoch 87/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0339 - val_loss: 0.0125\n",
      "Epoch 88/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 89/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0138 - val_loss: 0.0187\n",
      "Epoch 90/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1077 - val_loss: 0.0201\n",
      "Epoch 91/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3197 - val_loss: 0.0144\n",
      "Epoch 92/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0423 - val_loss: 0.0149\n",
      "Epoch 93/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0337 - val_loss: 0.0155\n",
      "Epoch 94/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0966 - val_loss: 0.0169\n",
      "Epoch 95/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0367 - val_loss: 0.0146\n",
      "Epoch 96/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0667 - val_loss: 0.0155\n",
      "Epoch 97/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0134\n",
      "Epoch 98/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0218 - val_loss: 0.0136\n",
      "Epoch 99/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0234 - val_loss: 0.0130\n",
      "Epoch 100/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1143 - val_loss: 0.0164\n",
      "Epoch 101/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0375 - val_loss: 0.0144\n",
      "Epoch 102/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0142\n",
      "Epoch 103/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0223 - val_loss: 0.0154\n",
      "Epoch 104/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0249 - val_loss: 0.0131\n",
      "Epoch 105/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0148 - val_loss: 0.0129\n",
      "Epoch 106/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0252 - val_loss: 0.0143\n",
      "Epoch 107/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0220 - val_loss: 0.0124\n",
      "Epoch 108/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 109/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0207 - val_loss: 0.0120\n",
      "Epoch 110/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0329 - val_loss: 0.0118\n",
      "Epoch 111/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0205 - val_loss: 0.0111\n",
      "Epoch 112/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 113/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0234 - val_loss: 0.0117\n",
      "Epoch 114/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0246 - val_loss: 0.0109\n",
      "Epoch 115/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 116/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0183 - val_loss: 0.0130\n",
      "Epoch 117/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0274 - val_loss: 0.0119\n",
      "Epoch 118/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 119/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 120/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0354 - val_loss: 0.0132\n",
      "Epoch 121/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0114\n",
      "Epoch 122/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 123/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 124/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 125/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 126/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 127/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0128\n",
      "Epoch 128/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0226 - val_loss: 0.0115\n",
      "Epoch 129/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0329 - val_loss: 0.0142\n",
      "Epoch 130/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0383 - val_loss: 0.0141\n",
      "Epoch 131/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0291 - val_loss: 0.0122\n",
      "Epoch 132/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0265 - val_loss: 0.0119\n",
      "Epoch 133/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 134/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0135 - val_loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0199 - val_loss: 0.0123\n",
      "Epoch 136/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 137/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0524 - val_loss: 0.0120\n",
      "Epoch 138/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 139/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 140/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 141/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 142/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0151 - val_loss: 0.0140\n",
      "Epoch 143/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0252 - val_loss: 0.0116\n",
      "Epoch 144/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0273 - val_loss: 0.0114\n",
      "Epoch 145/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0236 - val_loss: 0.0129\n",
      "Epoch 146/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 147/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0193 - val_loss: 0.0110\n",
      "Epoch 148/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0769 - val_loss: 0.0115\n",
      "Epoch 149/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0151 - val_loss: 0.0125\n",
      "Epoch 150/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0112\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "usa, MAE: 38775.83, MAPE: 0.025, R2: 0.980\n",
      "SVM Model - AIC: 72532.59, BIC: 72810.81\n",
      "Hyperparameters: lookback=6, n_layers=2\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 65/102\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6071  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5060 - val_loss: 0.0637\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0776 - val_loss: 0.0576\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0513 - val_loss: 0.0579\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0432 - val_loss: 0.0422\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0457 - val_loss: 0.0499\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0306\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0409 - val_loss: 0.0417\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0241\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0304 - val_loss: 0.0286\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0264 - val_loss: 0.0306\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0307 - val_loss: 0.0358\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0310 - val_loss: 0.0240\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0262 - val_loss: 0.0197\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0207 - val_loss: 0.0305\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0250 - val_loss: 0.0199\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0232 - val_loss: 0.0181\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - val_loss: 0.0261\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - val_loss: 0.0205\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - val_loss: 0.0142\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - val_loss: 0.0227\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - val_loss: 0.0147\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0211 - val_loss: 0.0152\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - val_loss: 0.0196\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - val_loss: 0.0217\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0465\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0147 - val_loss: 0.0186\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0157 - val_loss: 0.0195\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - val_loss: 0.0132\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - val_loss: 0.0178\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 - val_loss: 0.0224\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 - val_loss: 0.0163\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0137\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0126\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0171\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0142\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 52/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 53/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 0.0205\n",
      "Epoch 54/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 55/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 56/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 57/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - val_loss: 0.0140\n",
      "Epoch 58/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 59/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 60/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 61/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 - val_loss: 0.0150\n",
      "Epoch 62/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0162\n",
      "Epoch 63/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 0.0139\n",
      "Epoch 64/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0089\n",
      "Epoch 65/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0124\n",
      "Epoch 66/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 67/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0138\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 69/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 70/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 71/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0116\n",
      "Epoch 72/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 73/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0109\n",
      "Epoch 74/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 75/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 76/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 77/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0105\n",
      "Epoch 78/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 79/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 80/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 81/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0098\n",
      "Epoch 82/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 83/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 84/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0096\n",
      "Epoch 85/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0111\n",
      "Epoch 86/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 87/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0098\n",
      "Epoch 88/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 89/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0117\n",
      "Epoch 90/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0091\n",
      "Epoch 91/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 92/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 93/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 94/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 95/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 96/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 97/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0094\n",
      "Epoch 98/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0151\n",
      "Epoch 99/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0120\n",
      "Epoch 100/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0100\n",
      "Epoch 101/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 102/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0100\n",
      "Epoch 103/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0105\n",
      "Epoch 104/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 105/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0079\n",
      "Epoch 106/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0099\n",
      "Epoch 107/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 108/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 109/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 110/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 111/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 112/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 113/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 114/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 115/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0092\n",
      "Epoch 116/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0087\n",
      "Epoch 117/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 118/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 119/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 120/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0083\n",
      "Epoch 121/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0087\n",
      "Epoch 122/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 123/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 124/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 125/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 126/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0116\n",
      "Epoch 127/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0086\n",
      "Epoch 128/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 129/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 130/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0103\n",
      "Epoch 131/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0094\n",
      "Epoch 132/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0093\n",
      "Epoch 133/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0090\n",
      "Epoch 134/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 136/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0099\n",
      "Epoch 137/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0086\n",
      "Epoch 138/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0088\n",
      "Epoch 139/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0077\n",
      "Epoch 140/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 141/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0095\n",
      "Epoch 142/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0122\n",
      "Epoch 143/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "Epoch 144/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 145/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 146/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0096\n",
      "Epoch 147/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0075\n",
      "Epoch 148/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 149/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0086\n",
      "Epoch 150/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0112\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "morocco, MAE: 8240.16, MAPE: 0.022, R2: 0.982\n",
      "SVM Model - AIC: 62504.52, BIC: 62805.44\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 67/508\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3787 - val_loss: 0.1133\n",
      "Epoch 2/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1118 - val_loss: 0.0763\n",
      "Epoch 3/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0744 - val_loss: 0.0591\n",
      "Epoch 4/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0562\n",
      "Epoch 5/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0493 - val_loss: 0.0417\n",
      "Epoch 6/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0426 - val_loss: 0.0385\n",
      "Epoch 7/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0392 - val_loss: 0.0422\n",
      "Epoch 8/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0364 - val_loss: 0.0351\n",
      "Epoch 9/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0337 - val_loss: 0.0373\n",
      "Epoch 10/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0367 - val_loss: 0.0345\n",
      "Epoch 11/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0320 - val_loss: 0.0374\n",
      "Epoch 12/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0378 - val_loss: 0.0326\n",
      "Epoch 13/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0308 - val_loss: 0.0327\n",
      "Epoch 14/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0308 - val_loss: 0.0316\n",
      "Epoch 15/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0303 - val_loss: 0.0399\n",
      "Epoch 16/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0290 - val_loss: 0.0308\n",
      "Epoch 17/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0292 - val_loss: 0.0315\n",
      "Epoch 18/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0277 - val_loss: 0.0312\n",
      "Epoch 19/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0285 - val_loss: 0.0368\n",
      "Epoch 20/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0288 - val_loss: 0.0325\n",
      "Epoch 21/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0266 - val_loss: 0.0304\n",
      "Epoch 22/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0272 - val_loss: 0.0327\n",
      "Epoch 23/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - val_loss: 0.0284\n",
      "Epoch 24/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - val_loss: 0.0298\n",
      "Epoch 25/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0240 - val_loss: 0.0305\n",
      "Epoch 26/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - val_loss: 0.0295\n",
      "Epoch 27/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0253 - val_loss: 0.0285\n",
      "Epoch 28/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0235 - val_loss: 0.0298\n",
      "Epoch 29/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - val_loss: 0.0294\n",
      "Epoch 30/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - val_loss: 0.0274\n",
      "Epoch 31/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - val_loss: 0.0284\n",
      "Epoch 32/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - val_loss: 0.0286\n",
      "Epoch 33/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - val_loss: 0.0283\n",
      "Epoch 34/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - val_loss: 0.0292\n",
      "Epoch 35/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0227 - val_loss: 0.0294\n",
      "Epoch 36/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0221 - val_loss: 0.0287\n",
      "Epoch 37/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0226 - val_loss: 0.0283\n",
      "Epoch 38/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0267\n",
      "Epoch 39/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0214 - val_loss: 0.0292\n",
      "Epoch 40/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0227 - val_loss: 0.0341\n",
      "Epoch 41/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0217 - val_loss: 0.0296\n",
      "Epoch 42/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0215 - val_loss: 0.0280\n",
      "Epoch 43/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0207 - val_loss: 0.0299\n",
      "Epoch 44/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0211 - val_loss: 0.0278\n",
      "Epoch 45/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0215 - val_loss: 0.0288\n",
      "Epoch 46/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0214 - val_loss: 0.0268\n",
      "Epoch 47/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0203 - val_loss: 0.0281\n",
      "Epoch 48/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0212 - val_loss: 0.0272\n",
      "Epoch 49/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - val_loss: 0.0291\n",
      "Epoch 50/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0203 - val_loss: 0.0294\n",
      "Epoch 51/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0203 - val_loss: 0.0273\n",
      "Epoch 52/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0202 - val_loss: 0.0285\n",
      "Epoch 53/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0204 - val_loss: 0.0300\n",
      "Epoch 54/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0201 - val_loss: 0.0384\n",
      "Epoch 55/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0219 - val_loss: 0.0278\n",
      "Epoch 56/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0194 - val_loss: 0.0284\n",
      "Epoch 57/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0202 - val_loss: 0.0280\n",
      "Epoch 58/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0194 - val_loss: 0.0288\n",
      "Epoch 59/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0282\n",
      "Epoch 60/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0197 - val_loss: 0.0291\n",
      "Epoch 61/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0296\n",
      "Epoch 62/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0190 - val_loss: 0.0279\n",
      "Epoch 63/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0186 - val_loss: 0.0283\n",
      "Epoch 64/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0275\n",
      "Epoch 65/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0191 - val_loss: 0.0293\n",
      "Epoch 66/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0272\n",
      "Epoch 67/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0301\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0282\n",
      "Epoch 69/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0290\n",
      "Epoch 70/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0174 - val_loss: 0.0286\n",
      "Epoch 71/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0278\n",
      "Epoch 72/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0183 - val_loss: 0.0288\n",
      "Epoch 73/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0275\n",
      "Epoch 74/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0169 - val_loss: 0.0289\n",
      "Epoch 75/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0282\n",
      "Epoch 76/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0171 - val_loss: 0.0298\n",
      "Epoch 77/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0284\n",
      "Epoch 78/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0176 - val_loss: 0.0314\n",
      "Epoch 79/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0301\n",
      "Epoch 80/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0167 - val_loss: 0.0285\n",
      "Epoch 81/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0301\n",
      "Epoch 82/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0290\n",
      "Epoch 83/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0167 - val_loss: 0.0294\n",
      "Epoch 84/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0297\n",
      "Epoch 85/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0295\n",
      "Epoch 86/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0302\n",
      "Epoch 87/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0288\n",
      "Epoch 88/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0302\n",
      "Epoch 89/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0328\n",
      "Epoch 90/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0301\n",
      "Epoch 91/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0167 - val_loss: 0.0299\n",
      "Epoch 92/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0292\n",
      "Epoch 93/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0309\n",
      "Epoch 94/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0308\n",
      "Epoch 95/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0152 - val_loss: 0.0303\n",
      "Epoch 96/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0297\n",
      "Epoch 97/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - val_loss: 0.0305\n",
      "Epoch 98/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0297\n",
      "Epoch 99/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0315\n",
      "Epoch 100/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0159 - val_loss: 0.0300\n",
      "Epoch 101/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0294\n",
      "Epoch 102/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0309\n",
      "Epoch 103/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0322\n",
      "Epoch 104/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0304\n",
      "Epoch 105/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0306\n",
      "Epoch 106/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0292\n",
      "Epoch 107/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0300\n",
      "Epoch 108/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0302\n",
      "Epoch 109/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0296\n",
      "Epoch 110/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0297\n",
      "Epoch 111/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0307\n",
      "Epoch 112/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0296\n",
      "Epoch 113/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0311\n",
      "Epoch 114/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0306\n",
      "Epoch 115/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0307\n",
      "Epoch 116/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0318\n",
      "Epoch 117/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0320\n",
      "Epoch 118/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0296\n",
      "Epoch 119/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0301\n",
      "Epoch 120/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0305\n",
      "Epoch 121/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0304\n",
      "Epoch 122/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0309\n",
      "Epoch 123/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0321\n",
      "Epoch 124/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0338\n",
      "Epoch 125/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0311\n",
      "Epoch 126/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0313\n",
      "Epoch 127/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0309\n",
      "Epoch 128/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0317\n",
      "Epoch 129/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0330\n",
      "Epoch 130/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0318\n",
      "Epoch 131/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0306\n",
      "Epoch 132/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0326\n",
      "Epoch 133/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0310\n",
      "Epoch 134/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0322\n",
      "Epoch 136/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0323\n",
      "Epoch 137/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0353\n",
      "Epoch 138/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0305\n",
      "Epoch 139/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0303\n",
      "Epoch 140/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0315\n",
      "Epoch 141/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0314\n",
      "Epoch 142/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0303\n",
      "Epoch 143/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0322\n",
      "Epoch 144/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0310\n",
      "Epoch 145/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0323\n",
      "Epoch 146/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0320\n",
      "Epoch 147/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0311\n",
      "Epoch 148/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0311\n",
      "Epoch 149/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0310\n",
      "Epoch 150/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0324\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "paraguay, MAE: 155.40, MAPE: 0.027, R2: 0.949\n",
      "SVM Model - AIC: 36765.87, BIC: 37044.08\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 67/582\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.5120 - val_loss: 0.0880\n",
      "Epoch 2/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2086 - val_loss: 0.0532\n",
      "Epoch 3/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1328 - val_loss: 0.0478\n",
      "Epoch 4/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0880 - val_loss: 0.0472\n",
      "Epoch 5/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0670 - val_loss: 0.0414\n",
      "Epoch 6/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1147 - val_loss: 0.0404\n",
      "Epoch 7/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4293 - val_loss: 0.0538\n",
      "Epoch 8/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3512 - val_loss: 0.0499\n",
      "Epoch 9/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0919 - val_loss: 0.0704\n",
      "Epoch 10/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1718 - val_loss: 0.0328\n",
      "Epoch 11/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1397 - val_loss: 0.0299\n",
      "Epoch 12/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0434 - val_loss: 0.0312\n",
      "Epoch 13/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1115 - val_loss: 0.0274\n",
      "Epoch 14/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0365 - val_loss: 0.0376\n",
      "Epoch 15/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1747 - val_loss: 0.0267\n",
      "Epoch 16/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0527 - val_loss: 0.0214\n",
      "Epoch 17/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0287 - val_loss: 0.0194\n",
      "Epoch 18/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0410 - val_loss: 0.0188\n",
      "Epoch 19/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0414 - val_loss: 0.0171\n",
      "Epoch 20/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0333 - val_loss: 0.0356\n",
      "Epoch 21/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0231 - val_loss: 0.0192\n",
      "Epoch 22/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0419 - val_loss: 0.0306\n",
      "Epoch 23/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6698 - val_loss: 0.0369\n",
      "Epoch 24/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2351 - val_loss: 0.0280\n",
      "Epoch 25/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2032 - val_loss: 0.0199\n",
      "Epoch 26/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0950 - val_loss: 0.0198\n",
      "Epoch 27/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0449 - val_loss: 0.0198\n",
      "Epoch 28/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0692 - val_loss: 0.0193\n",
      "Epoch 29/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0475 - val_loss: 0.0177\n",
      "Epoch 30/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0214 - val_loss: 0.0167\n",
      "Epoch 31/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - val_loss: 0.0167\n",
      "Epoch 32/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0184\n",
      "Epoch 33/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0514 - val_loss: 0.0210\n",
      "Epoch 34/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0673 - val_loss: 0.0159\n",
      "Epoch 35/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 36/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0429 - val_loss: 0.0179\n",
      "Epoch 37/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0484 - val_loss: 0.0173\n",
      "Epoch 38/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0507 - val_loss: 0.0151\n",
      "Epoch 39/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0147\n",
      "Epoch 40/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - val_loss: 0.0172\n",
      "Epoch 41/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0278 - val_loss: 0.0194\n",
      "Epoch 42/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0371 - val_loss: 0.0175\n",
      "Epoch 43/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0452 - val_loss: 0.0165\n",
      "Epoch 44/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0281 - val_loss: 0.0147\n",
      "Epoch 45/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0262 - val_loss: 0.0143\n",
      "Epoch 46/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0204\n",
      "Epoch 47/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0459 - val_loss: 0.0241\n",
      "Epoch 48/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0537 - val_loss: 0.0134\n",
      "Epoch 49/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0297 - val_loss: 0.0146\n",
      "Epoch 50/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0613 - val_loss: 0.0171\n",
      "Epoch 51/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0415 - val_loss: 0.0173\n",
      "Epoch 52/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0299 - val_loss: 0.0227\n",
      "Epoch 53/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0299 - val_loss: 0.0150\n",
      "Epoch 54/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0290 - val_loss: 0.0144\n",
      "Epoch 55/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0275 - val_loss: 0.0161\n",
      "Epoch 56/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2757 - val_loss: 0.0170\n",
      "Epoch 57/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0544 - val_loss: 0.0253\n",
      "Epoch 58/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0403 - val_loss: 0.0149\n",
      "Epoch 59/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0420 - val_loss: 0.0176\n",
      "Epoch 60/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2593 - val_loss: 0.0229\n",
      "Epoch 61/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0497 - val_loss: 0.0193\n",
      "Epoch 62/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0315 - val_loss: 0.0162\n",
      "Epoch 63/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0293 - val_loss: 0.0176\n",
      "Epoch 64/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0524 - val_loss: 0.0149\n",
      "Epoch 65/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0174 - val_loss: 0.0197\n",
      "Epoch 66/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0332 - val_loss: 0.0169\n",
      "Epoch 67/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0632 - val_loss: 0.0143\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0360 - val_loss: 0.0521\n",
      "Epoch 69/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1176 - val_loss: 0.0173\n",
      "Epoch 70/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0329 - val_loss: 0.0154\n",
      "Epoch 71/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0295 - val_loss: 0.0146\n",
      "Epoch 72/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0217 - val_loss: 0.0148\n",
      "Epoch 73/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0139\n",
      "Epoch 74/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 75/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 76/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 77/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - val_loss: 0.0151\n",
      "Epoch 78/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0388 - val_loss: 0.0125\n",
      "Epoch 79/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0210 - val_loss: 0.0129\n",
      "Epoch 80/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 81/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0945 - val_loss: 0.0142\n",
      "Epoch 82/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1616 - val_loss: 0.0133\n",
      "Epoch 83/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0260 - val_loss: 0.0122\n",
      "Epoch 84/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 85/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0133\n",
      "Epoch 86/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0318 - val_loss: 0.0139\n",
      "Epoch 87/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - val_loss: 0.0123\n",
      "Epoch 88/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 89/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 90/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - val_loss: 0.0136\n",
      "Epoch 91/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1269 - val_loss: 0.0183\n",
      "Epoch 92/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0288 - val_loss: 0.0175\n",
      "Epoch 93/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0396 - val_loss: 0.0153\n",
      "Epoch 94/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0212 - val_loss: 0.0147\n",
      "Epoch 95/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0142\n",
      "Epoch 96/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0277 - val_loss: 0.0134\n",
      "Epoch 97/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - val_loss: 0.0140\n",
      "Epoch 98/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - val_loss: 0.0161\n",
      "Epoch 99/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0210 - val_loss: 0.0132\n",
      "Epoch 100/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 101/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 102/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0380 - val_loss: 0.0151\n",
      "Epoch 103/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0412 - val_loss: 0.0123\n",
      "Epoch 104/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0121\n",
      "Epoch 105/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 106/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - val_loss: 0.0159\n",
      "Epoch 107/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0962 - val_loss: 0.0135\n",
      "Epoch 108/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 109/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0132\n",
      "Epoch 110/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0221 - val_loss: 0.0116\n",
      "Epoch 111/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0120\n",
      "Epoch 112/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 113/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0128\n",
      "Epoch 114/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 115/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - val_loss: 0.0150\n",
      "Epoch 116/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0162 - val_loss: 0.0128\n",
      "Epoch 117/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0297 - val_loss: 0.0123\n",
      "Epoch 118/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - val_loss: 0.0169\n",
      "Epoch 119/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0288 - val_loss: 0.0114\n",
      "Epoch 120/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0265 - val_loss: 0.0118\n",
      "Epoch 121/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0418 - val_loss: 0.0177\n",
      "Epoch 122/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0160\n",
      "Epoch 123/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0300 - val_loss: 0.0131\n",
      "Epoch 124/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0339 - val_loss: 0.0155\n",
      "Epoch 125/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0276 - val_loss: 0.0118\n",
      "Epoch 126/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0119\n",
      "Epoch 127/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0116\n",
      "Epoch 128/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 129/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 130/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 131/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - val_loss: 0.0154\n",
      "Epoch 132/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0298 - val_loss: 0.0123\n",
      "Epoch 133/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0216 - val_loss: 0.0119\n",
      "Epoch 134/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0222 - val_loss: 0.0114\n",
      "Epoch 136/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 137/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0310 - val_loss: 0.0110\n",
      "Epoch 138/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 139/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 140/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 141/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0688 - val_loss: 0.0146\n",
      "Epoch 142/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0767 - val_loss: 0.0125\n",
      "Epoch 143/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 144/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 145/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 146/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 147/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 148/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 149/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0217 - val_loss: 0.0142\n",
      "Epoch 150/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0490 - val_loss: 0.0115\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "usa, MAE: 39507.75, MAPE: 0.025, R2: 0.980\n",
      "SVM Model - AIC: 72653.77, BIC: 72931.98\n",
      "Hyperparameters: lookback=12, n_layers=1\n",
      "Epoch 1/150\n",
      "\u001b[1m 73/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3892 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3313 - val_loss: 0.0607\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0553 - val_loss: 0.0392\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0461 - val_loss: 0.0298\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - val_loss: 0.0661\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0299 - val_loss: 0.0243\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0282 - val_loss: 0.0203\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 - val_loss: 0.0241\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0223 - val_loss: 0.0196\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0212 - val_loss: 0.0159\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0237 - val_loss: 0.0167\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - val_loss: 0.0152\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0137\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0304 - val_loss: 0.0211\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - val_loss: 0.0275\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0653\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0355\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0160\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0160\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0232\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0206\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0079\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0091\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0084\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0114\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0179\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0111\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 52/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0139\n",
      "Epoch 53/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0122\n",
      "Epoch 54/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 55/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 56/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 57/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0098\n",
      "Epoch 58/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 59/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0149\n",
      "Epoch 60/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0130\n",
      "Epoch 61/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0131\n",
      "Epoch 62/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 63/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0092\n",
      "Epoch 64/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0079\n",
      "Epoch 65/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0132\n",
      "Epoch 66/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0126\n",
      "Epoch 67/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0089\n",
      "Epoch 69/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 70/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 71/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 72/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 73/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0117\n",
      "Epoch 74/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0110\n",
      "Epoch 75/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 76/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 77/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 78/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0134\n",
      "Epoch 79/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 80/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0126\n",
      "Epoch 81/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 82/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 83/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 84/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0096\n",
      "Epoch 85/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0112\n",
      "Epoch 86/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 87/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0093\n",
      "Epoch 88/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 89/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 90/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0098\n",
      "Epoch 91/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 92/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 93/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 94/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0100\n",
      "Epoch 95/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 96/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0099\n",
      "Epoch 97/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 98/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 99/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 100/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0121\n",
      "Epoch 101/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0100\n",
      "Epoch 102/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0084\n",
      "Epoch 103/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0104\n",
      "Epoch 104/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 105/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 106/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0119\n",
      "Epoch 107/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0119\n",
      "Epoch 108/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 109/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0081\n",
      "Epoch 110/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 111/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 112/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 113/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0114\n",
      "Epoch 114/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 115/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 116/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 117/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0091\n",
      "Epoch 118/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 119/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0080\n",
      "Epoch 120/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 121/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0083\n",
      "Epoch 122/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 123/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 124/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 125/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0117\n",
      "Epoch 126/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0071\n",
      "Epoch 127/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 128/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0093\n",
      "Epoch 129/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0126\n",
      "Epoch 130/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 131/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0119\n",
      "Epoch 132/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 133/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 134/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0135\n",
      "Epoch 136/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0104\n",
      "Epoch 137/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0119\n",
      "Epoch 138/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0093\n",
      "Epoch 139/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0162\n",
      "Epoch 140/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 141/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0106\n",
      "Epoch 142/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0110\n",
      "Epoch 143/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0095\n",
      "Epoch 144/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0087\n",
      "Epoch 145/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0093\n",
      "Epoch 146/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 147/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0087\n",
      "Epoch 148/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0080\n",
      "Epoch 149/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0085\n",
      "Epoch 150/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0108\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "morocco, MAE: 7946.60, MAPE: 0.023, R2: 0.983\n",
      "SVM Model - AIC: 62269.45, BIC: 62570.38\n",
      "Epoch 1/150\n",
      "\u001b[1m 71/508\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2934 - val_loss: 0.0946\n",
      "Epoch 2/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0692 - val_loss: 0.0632\n",
      "Epoch 3/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0557 - val_loss: 0.0511\n",
      "Epoch 4/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0424 - val_loss: 0.0413\n",
      "Epoch 5/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0421 - val_loss: 0.0410\n",
      "Epoch 6/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0374 - val_loss: 0.0384\n",
      "Epoch 7/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0492 - val_loss: 0.0366\n",
      "Epoch 8/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0335 - val_loss: 0.0359\n",
      "Epoch 9/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0320 - val_loss: 0.0339\n",
      "Epoch 10/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0324 - val_loss: 0.0336\n",
      "Epoch 11/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0325 - val_loss: 0.0344\n",
      "Epoch 12/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0300 - val_loss: 0.0328\n",
      "Epoch 13/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0296 - val_loss: 0.0320\n",
      "Epoch 14/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0300 - val_loss: 0.0322\n",
      "Epoch 15/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0304 - val_loss: 0.0320\n",
      "Epoch 16/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0288 - val_loss: 0.0311\n",
      "Epoch 17/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0296 - val_loss: 0.0306\n",
      "Epoch 18/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0267 - val_loss: 0.0304\n",
      "Epoch 19/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0280 - val_loss: 0.0304\n",
      "Epoch 20/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - val_loss: 0.0311\n",
      "Epoch 21/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0266 - val_loss: 0.0296\n",
      "Epoch 22/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - val_loss: 0.0349\n",
      "Epoch 23/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0273 - val_loss: 0.0295\n",
      "Epoch 24/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - val_loss: 0.0301\n",
      "Epoch 25/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - val_loss: 0.0318\n",
      "Epoch 26/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - val_loss: 0.0293\n",
      "Epoch 27/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - val_loss: 0.0298\n",
      "Epoch 28/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - val_loss: 0.0305\n",
      "Epoch 29/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - val_loss: 0.0295\n",
      "Epoch 30/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - val_loss: 0.0297\n",
      "Epoch 31/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - val_loss: 0.0305\n",
      "Epoch 32/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - val_loss: 0.0298\n",
      "Epoch 33/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - val_loss: 0.0305\n",
      "Epoch 34/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - val_loss: 0.0304\n",
      "Epoch 35/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0294\n",
      "Epoch 36/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0290\n",
      "Epoch 37/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0223 - val_loss: 0.0293\n",
      "Epoch 38/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0235 - val_loss: 0.0276\n",
      "Epoch 39/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - val_loss: 0.0290\n",
      "Epoch 40/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0224 - val_loss: 0.0290\n",
      "Epoch 41/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0286\n",
      "Epoch 42/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0212 - val_loss: 0.0276\n",
      "Epoch 43/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0220 - val_loss: 0.0283\n",
      "Epoch 44/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0289\n",
      "Epoch 45/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0283\n",
      "Epoch 46/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0231 - val_loss: 0.0282\n",
      "Epoch 47/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0216 - val_loss: 0.0285\n",
      "Epoch 48/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0225 - val_loss: 0.0279\n",
      "Epoch 49/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0205 - val_loss: 0.0271\n",
      "Epoch 50/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0221 - val_loss: 0.0295\n",
      "Epoch 51/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0212 - val_loss: 0.0287\n",
      "Epoch 52/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0206 - val_loss: 0.0293\n",
      "Epoch 53/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0206 - val_loss: 0.0295\n",
      "Epoch 54/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0204 - val_loss: 0.0280\n",
      "Epoch 55/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0201 - val_loss: 0.0276\n",
      "Epoch 56/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0207 - val_loss: 0.0284\n",
      "Epoch 57/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0201 - val_loss: 0.0278\n",
      "Epoch 58/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0205 - val_loss: 0.0283\n",
      "Epoch 59/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0211 - val_loss: 0.0290\n",
      "Epoch 60/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0210 - val_loss: 0.0278\n",
      "Epoch 61/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0200 - val_loss: 0.0289\n",
      "Epoch 62/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0200 - val_loss: 0.0282\n",
      "Epoch 63/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0198 - val_loss: 0.0287\n",
      "Epoch 64/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0207 - val_loss: 0.0282\n",
      "Epoch 65/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0313\n",
      "Epoch 66/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0205 - val_loss: 0.0284\n",
      "Epoch 67/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0278\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0203 - val_loss: 0.0289\n",
      "Epoch 69/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0293\n",
      "Epoch 70/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0206 - val_loss: 0.0292\n",
      "Epoch 71/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0198 - val_loss: 0.0294\n",
      "Epoch 72/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0189 - val_loss: 0.0288\n",
      "Epoch 73/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0192 - val_loss: 0.0287\n",
      "Epoch 74/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0280\n",
      "Epoch 75/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0279\n",
      "Epoch 76/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0293\n",
      "Epoch 77/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0192 - val_loss: 0.0289\n",
      "Epoch 78/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0191 - val_loss: 0.0284\n",
      "Epoch 79/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0194 - val_loss: 0.0279\n",
      "Epoch 80/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0295\n",
      "Epoch 81/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0289\n",
      "Epoch 82/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0293\n",
      "Epoch 83/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0297\n",
      "Epoch 84/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0189 - val_loss: 0.0284\n",
      "Epoch 85/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0189 - val_loss: 0.0314\n",
      "Epoch 86/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - val_loss: 0.0304\n",
      "Epoch 87/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0281\n",
      "Epoch 88/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0176 - val_loss: 0.0278\n",
      "Epoch 89/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0178 - val_loss: 0.0291\n",
      "Epoch 90/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0185 - val_loss: 0.0283\n",
      "Epoch 91/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - val_loss: 0.0293\n",
      "Epoch 92/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 0.0312\n",
      "Epoch 93/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0311\n",
      "Epoch 94/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0184 - val_loss: 0.0304\n",
      "Epoch 95/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0291\n",
      "Epoch 96/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0171 - val_loss: 0.0292\n",
      "Epoch 97/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0298\n",
      "Epoch 98/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0177 - val_loss: 0.0302\n",
      "Epoch 99/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0296\n",
      "Epoch 100/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0178 - val_loss: 0.0299\n",
      "Epoch 101/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0286\n",
      "Epoch 102/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0175 - val_loss: 0.0279\n",
      "Epoch 103/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0178 - val_loss: 0.0307\n",
      "Epoch 104/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0175 - val_loss: 0.0300\n",
      "Epoch 105/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0174 - val_loss: 0.0298\n",
      "Epoch 106/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0291\n",
      "Epoch 107/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0168 - val_loss: 0.0300\n",
      "Epoch 108/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0185 - val_loss: 0.0294\n",
      "Epoch 109/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0321\n",
      "Epoch 110/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0202 - val_loss: 0.0289\n",
      "Epoch 111/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0286\n",
      "Epoch 112/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0168 - val_loss: 0.0292\n",
      "Epoch 113/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0174 - val_loss: 0.0304\n",
      "Epoch 114/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0286\n",
      "Epoch 115/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0283\n",
      "Epoch 116/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0168 - val_loss: 0.0293\n",
      "Epoch 117/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0296\n",
      "Epoch 118/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0281\n",
      "Epoch 119/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0288\n",
      "Epoch 120/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0291\n",
      "Epoch 121/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0298\n",
      "Epoch 122/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0169 - val_loss: 0.0297\n",
      "Epoch 123/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - val_loss: 0.0283\n",
      "Epoch 124/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0300\n",
      "Epoch 125/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0293\n",
      "Epoch 126/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0296\n",
      "Epoch 127/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0287\n",
      "Epoch 128/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0162 - val_loss: 0.0300\n",
      "Epoch 129/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0299\n",
      "Epoch 130/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0286\n",
      "Epoch 131/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0167 - val_loss: 0.0287\n",
      "Epoch 132/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0159 - val_loss: 0.0306\n",
      "Epoch 133/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0283\n",
      "Epoch 134/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0298\n",
      "Epoch 136/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0296\n",
      "Epoch 137/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0298\n",
      "Epoch 138/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0298\n",
      "Epoch 139/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0292\n",
      "Epoch 140/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0289\n",
      "Epoch 141/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0294\n",
      "Epoch 142/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0297\n",
      "Epoch 143/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0149 - val_loss: 0.0286\n",
      "Epoch 144/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0294\n",
      "Epoch 145/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0290\n",
      "Epoch 146/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0303\n",
      "Epoch 147/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0295\n",
      "Epoch 148/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0294\n",
      "Epoch 149/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0295\n",
      "Epoch 150/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0299\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "paraguay, MAE: 148.11, MAPE: 0.026, R2: 0.953\n",
      "SVM Model - AIC: 36454.68, BIC: 36732.89\n",
      "Epoch 1/150\n",
      "\u001b[1m 46/582\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.9818 - val_loss: 0.0679\n",
      "Epoch 2/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1683 - val_loss: 0.0584\n",
      "Epoch 3/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1391 - val_loss: 0.0450\n",
      "Epoch 4/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1505 - val_loss: 0.0370\n",
      "Epoch 5/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0587 - val_loss: 0.0333\n",
      "Epoch 6/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0588 - val_loss: 0.0273\n",
      "Epoch 7/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0880 - val_loss: 0.0222\n",
      "Epoch 8/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0273 - val_loss: 0.0196\n",
      "Epoch 9/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0306 - val_loss: 0.0176\n",
      "Epoch 10/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0726 - val_loss: 0.0275\n",
      "Epoch 11/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0807 - val_loss: 0.0232\n",
      "Epoch 12/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0593 - val_loss: 0.0794\n",
      "Epoch 13/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0636 - val_loss: 0.0298\n",
      "Epoch 14/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0506 - val_loss: 0.0209\n",
      "Epoch 15/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1868 - val_loss: 0.0211\n",
      "Epoch 16/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0323 - val_loss: 0.0187\n",
      "Epoch 17/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0331 - val_loss: 0.0175\n",
      "Epoch 18/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0463 - val_loss: 0.0187\n",
      "Epoch 19/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1072 - val_loss: 0.0390\n",
      "Epoch 20/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0909 - val_loss: 0.0217\n",
      "Epoch 21/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0345 - val_loss: 0.0185\n",
      "Epoch 22/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - val_loss: 0.0181\n",
      "Epoch 23/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0227 - val_loss: 0.0175\n",
      "Epoch 24/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0274 - val_loss: 0.0170\n",
      "Epoch 25/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0223 - val_loss: 0.0186\n",
      "Epoch 26/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0345 - val_loss: 0.0161\n",
      "Epoch 27/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0206 - val_loss: 0.0175\n",
      "Epoch 28/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0383 - val_loss: 0.0156\n",
      "Epoch 29/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - val_loss: 0.0148\n",
      "Epoch 30/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0143\n",
      "Epoch 31/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0169\n",
      "Epoch 32/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0350 - val_loss: 0.0160\n",
      "Epoch 33/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0333 - val_loss: 0.0181\n",
      "Epoch 34/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0142\n",
      "Epoch 35/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0141\n",
      "Epoch 36/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0395 - val_loss: 0.0139\n",
      "Epoch 37/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0229 - val_loss: 0.0141\n",
      "Epoch 38/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0128\n",
      "Epoch 39/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0496 - val_loss: 0.0614\n",
      "Epoch 40/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0482 - val_loss: 0.0176\n",
      "Epoch 41/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - val_loss: 0.0162\n",
      "Epoch 42/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0154\n",
      "Epoch 43/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0178 - val_loss: 0.0150\n",
      "Epoch 44/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0139\n",
      "Epoch 45/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 46/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 47/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 48/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 49/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 50/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 51/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 52/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 53/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 54/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1141 - val_loss: 0.0131\n",
      "Epoch 55/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 56/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0144\n",
      "Epoch 57/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 58/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 59/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0172 - val_loss: 0.0147\n",
      "Epoch 60/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 61/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0127\n",
      "Epoch 62/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 63/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 64/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 65/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0308 - val_loss: 0.0298\n",
      "Epoch 66/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3114 - val_loss: 0.0284\n",
      "Epoch 67/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1588 - val_loss: 0.0228\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1377 - val_loss: 0.0288\n",
      "Epoch 69/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0663 - val_loss: 0.0229\n",
      "Epoch 70/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0519 - val_loss: 0.0192\n",
      "Epoch 71/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0323 - val_loss: 0.0170\n",
      "Epoch 72/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0171\n",
      "Epoch 73/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0200 - val_loss: 0.0155\n",
      "Epoch 74/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0158\n",
      "Epoch 75/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0214 - val_loss: 0.0145\n",
      "Epoch 76/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - val_loss: 0.0142\n",
      "Epoch 77/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0192 - val_loss: 0.0137\n",
      "Epoch 78/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 79/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0150\n",
      "Epoch 80/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0181 - val_loss: 0.0139\n",
      "Epoch 81/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0328\n",
      "Epoch 82/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0289 - val_loss: 0.0155\n",
      "Epoch 83/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0267 - val_loss: 0.0121\n",
      "Epoch 84/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0123\n",
      "Epoch 85/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0135\n",
      "Epoch 86/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1007 - val_loss: 0.0259\n",
      "Epoch 87/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0949 - val_loss: 0.0204\n",
      "Epoch 88/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0638 - val_loss: 0.0184\n",
      "Epoch 89/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0436 - val_loss: 0.0171\n",
      "Epoch 90/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0313 - val_loss: 0.0156\n",
      "Epoch 91/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0769 - val_loss: 0.0173\n",
      "Epoch 92/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0259 - val_loss: 0.0157\n",
      "Epoch 93/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0198 - val_loss: 0.0157\n",
      "Epoch 94/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0152\n",
      "Epoch 95/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0153\n",
      "Epoch 96/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0224 - val_loss: 0.0139\n",
      "Epoch 97/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 98/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0146 - val_loss: 0.0135\n",
      "Epoch 99/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 100/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0130\n",
      "Epoch 101/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - val_loss: 0.0160\n",
      "Epoch 102/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - val_loss: 0.0135\n",
      "Epoch 103/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0266 - val_loss: 0.0125\n",
      "Epoch 104/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0128\n",
      "Epoch 105/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0185 - val_loss: 0.0281\n",
      "Epoch 106/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0183 - val_loss: 0.0128\n",
      "Epoch 107/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0118\n",
      "Epoch 108/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0191 - val_loss: 0.0125\n",
      "Epoch 109/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0123\n",
      "Epoch 110/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0211 - val_loss: 0.0114\n",
      "Epoch 111/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0130\n",
      "Epoch 112/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0127\n",
      "Epoch 113/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0114\n",
      "Epoch 114/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 115/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 116/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 117/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5349 - val_loss: 0.0462\n",
      "Epoch 118/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8700 - val_loss: 0.0729\n",
      "Epoch 119/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5090 - val_loss: 0.0595\n",
      "Epoch 120/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2027 - val_loss: 0.0627\n",
      "Epoch 121/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3698 - val_loss: 0.0678\n",
      "Epoch 122/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1382 - val_loss: 0.0516\n",
      "Epoch 123/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0845 - val_loss: 0.0426\n",
      "Epoch 124/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0701 - val_loss: 0.0396\n",
      "Epoch 125/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0818 - val_loss: 0.0330\n",
      "Epoch 126/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0447 - val_loss: 0.0315\n",
      "Epoch 127/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0483 - val_loss: 0.0405\n",
      "Epoch 128/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1222 - val_loss: 0.0271\n",
      "Epoch 129/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0328 - val_loss: 0.0252\n",
      "Epoch 130/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0325 - val_loss: 0.0230\n",
      "Epoch 131/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0314 - val_loss: 0.0214\n",
      "Epoch 132/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0303 - val_loss: 0.0197\n",
      "Epoch 133/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0268 - val_loss: 0.0210\n",
      "Epoch 134/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - val_loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0302 - val_loss: 0.0179\n",
      "Epoch 136/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - val_loss: 0.0188\n",
      "Epoch 137/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0259 - val_loss: 0.0177\n",
      "Epoch 138/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - val_loss: 0.0167\n",
      "Epoch 139/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - val_loss: 0.0189\n",
      "Epoch 140/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0225 - val_loss: 0.0167\n",
      "Epoch 141/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - val_loss: 0.0167\n",
      "Epoch 142/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0197 - val_loss: 0.0149\n",
      "Epoch 143/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 144/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0302 - val_loss: 0.0133\n",
      "Epoch 145/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0200\n",
      "Epoch 146/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0787 - val_loss: 0.0263\n",
      "Epoch 147/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0398 - val_loss: 0.0174\n",
      "Epoch 148/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1951 - val_loss: 0.0974\n",
      "Epoch 149/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7176 - val_loss: 0.0771\n",
      "Epoch 150/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7130 - val_loss: 0.0994\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "usa, MAE: 125964.75, MAPE: 0.082, R2: 0.824\n",
      "SVM Model - AIC: 80167.36, BIC: 80445.58\n",
      "Hyperparameters: lookback=12, n_layers=2\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 38/102\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2536  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7606 - val_loss: 0.0834\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1167 - val_loss: 0.0638\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0637 - val_loss: 0.0515\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0555 - val_loss: 0.0483\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0475 - val_loss: 0.0314\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0445 - val_loss: 0.0300\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0342 - val_loss: 0.0231\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.0278\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0206\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.0222\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0320\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0214\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0200\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0167\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0219\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0185\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0149\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0159 - val_loss: 0.0220\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0160 - val_loss: 0.0137\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0144 - val_loss: 0.0167\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0150 - val_loss: 0.0128\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0413\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0108\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0149 - val_loss: 0.0141\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0160\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0257\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0092\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0114\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0132\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0118\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 52/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0154\n",
      "Epoch 53/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 54/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 55/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0120\n",
      "Epoch 56/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 57/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 58/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 59/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 60/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 61/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 62/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 63/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0121\n",
      "Epoch 64/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0109\n",
      "Epoch 65/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 66/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 67/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0154\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 69/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 70/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0112\n",
      "Epoch 71/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 72/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 73/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 74/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 75/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 76/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 77/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 78/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 79/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 80/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - val_loss: 0.0131\n",
      "Epoch 81/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 82/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 83/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0108\n",
      "Epoch 84/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 85/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 86/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 87/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 88/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 89/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0124\n",
      "Epoch 90/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 91/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 92/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 93/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 94/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 95/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 96/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0107\n",
      "Epoch 97/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 98/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 99/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0121\n",
      "Epoch 100/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0111\n",
      "Epoch 101/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 102/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 103/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 104/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 105/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 106/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 107/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0090\n",
      "Epoch 108/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 109/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 110/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0086\n",
      "Epoch 111/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 112/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0122\n",
      "Epoch 113/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0086\n",
      "Epoch 114/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 115/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 116/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 117/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 118/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 119/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 120/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 121/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 122/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0089\n",
      "Epoch 123/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0075\n",
      "Epoch 124/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 125/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0120\n",
      "Epoch 126/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 127/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0089\n",
      "Epoch 128/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 129/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0124\n",
      "Epoch 130/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 131/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0081\n",
      "Epoch 132/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0095\n",
      "Epoch 133/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0135\n",
      "Epoch 134/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0092\n",
      "Epoch 136/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 137/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 138/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 139/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0089\n",
      "Epoch 140/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0090\n",
      "Epoch 141/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0079\n",
      "Epoch 142/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0088\n",
      "Epoch 143/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0114\n",
      "Epoch 144/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 145/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0098\n",
      "Epoch 146/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 147/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 148/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0088\n",
      "Epoch 149/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0088\n",
      "Epoch 150/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0091\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "morocco, MAE: 7447.31, MAPE: 0.020, R2: 0.985\n",
      "SVM Model - AIC: 61848.95, BIC: 62149.88\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 40/508\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3392 - val_loss: 0.1342\n",
      "Epoch 2/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1008 - val_loss: 0.0775\n",
      "Epoch 3/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0697 - val_loss: 0.0625\n",
      "Epoch 4/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 5/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0424 - val_loss: 0.0404\n",
      "Epoch 6/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0546\n",
      "Epoch 7/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0375\n",
      "Epoch 8/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0347 - val_loss: 0.0339\n",
      "Epoch 9/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.0328\n",
      "Epoch 10/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0353\n",
      "Epoch 11/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0337 - val_loss: 0.0316\n",
      "Epoch 12/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0306\n",
      "Epoch 13/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0320\n",
      "Epoch 14/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0332\n",
      "Epoch 15/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0295 - val_loss: 0.0366\n",
      "Epoch 16/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0333\n",
      "Epoch 17/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.0339\n",
      "Epoch 18/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0329\n",
      "Epoch 19/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0322\n",
      "Epoch 20/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0307\n",
      "Epoch 21/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0303\n",
      "Epoch 22/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0322\n",
      "Epoch 23/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 24/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0295 - val_loss: 0.0292\n",
      "Epoch 25/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0312\n",
      "Epoch 26/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0302\n",
      "Epoch 27/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0304\n",
      "Epoch 28/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0282\n",
      "Epoch 29/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0308\n",
      "Epoch 30/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0307\n",
      "Epoch 31/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0314\n",
      "Epoch 32/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0300\n",
      "Epoch 33/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0288\n",
      "Epoch 34/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0305\n",
      "Epoch 35/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0304\n",
      "Epoch 36/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0285\n",
      "Epoch 37/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0365\n",
      "Epoch 38/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0284\n",
      "Epoch 39/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0287\n",
      "Epoch 40/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0274\n",
      "Epoch 41/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0268\n",
      "Epoch 42/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0300\n",
      "Epoch 43/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0301\n",
      "Epoch 44/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0289\n",
      "Epoch 45/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0278\n",
      "Epoch 46/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0285\n",
      "Epoch 47/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0299\n",
      "Epoch 48/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0286\n",
      "Epoch 49/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0292\n",
      "Epoch 50/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0267\n",
      "Epoch 51/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0285\n",
      "Epoch 52/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0302\n",
      "Epoch 53/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0283\n",
      "Epoch 54/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0266\n",
      "Epoch 55/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0265\n",
      "Epoch 56/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0274\n",
      "Epoch 57/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0276\n",
      "Epoch 58/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0262\n",
      "Epoch 59/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0292\n",
      "Epoch 60/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194 - val_loss: 0.0276\n",
      "Epoch 61/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0267\n",
      "Epoch 62/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0267\n",
      "Epoch 63/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0277\n",
      "Epoch 64/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0282\n",
      "Epoch 65/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0291\n",
      "Epoch 66/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0271\n",
      "Epoch 67/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0289\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0280\n",
      "Epoch 69/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0278\n",
      "Epoch 70/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0304\n",
      "Epoch 71/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0303\n",
      "Epoch 72/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0283\n",
      "Epoch 73/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0279\n",
      "Epoch 74/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0296\n",
      "Epoch 75/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0299\n",
      "Epoch 76/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0290\n",
      "Epoch 77/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0289\n",
      "Epoch 78/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0311\n",
      "Epoch 79/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0293\n",
      "Epoch 80/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0298\n",
      "Epoch 81/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0295\n",
      "Epoch 82/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0284\n",
      "Epoch 83/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0289\n",
      "Epoch 84/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159 - val_loss: 0.0275\n",
      "Epoch 85/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0282\n",
      "Epoch 86/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0301\n",
      "Epoch 87/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0275\n",
      "Epoch 88/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0306\n",
      "Epoch 89/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0158 - val_loss: 0.0289\n",
      "Epoch 90/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0157 - val_loss: 0.0319\n",
      "Epoch 91/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0288\n",
      "Epoch 92/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0293\n",
      "Epoch 93/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0157 - val_loss: 0.0298\n",
      "Epoch 94/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0152 - val_loss: 0.0281\n",
      "Epoch 95/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0155 - val_loss: 0.0303\n",
      "Epoch 96/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - val_loss: 0.0294\n",
      "Epoch 97/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0152 - val_loss: 0.0297\n",
      "Epoch 98/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0153 - val_loss: 0.0302\n",
      "Epoch 99/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0153 - val_loss: 0.0300\n",
      "Epoch 100/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0155 - val_loss: 0.0291\n",
      "Epoch 101/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0303\n",
      "Epoch 102/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0149 - val_loss: 0.0315\n",
      "Epoch 103/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0146 - val_loss: 0.0307\n",
      "Epoch 104/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0139 - val_loss: 0.0298\n",
      "Epoch 105/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0154 - val_loss: 0.0320\n",
      "Epoch 106/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0152 - val_loss: 0.0303\n",
      "Epoch 107/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0139 - val_loss: 0.0326\n",
      "Epoch 108/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0141 - val_loss: 0.0317\n",
      "Epoch 109/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0140 - val_loss: 0.0302\n",
      "Epoch 110/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - val_loss: 0.0301\n",
      "Epoch 111/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0151 - val_loss: 0.0316\n",
      "Epoch 112/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0137 - val_loss: 0.0304\n",
      "Epoch 113/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - val_loss: 0.0322\n",
      "Epoch 114/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0140 - val_loss: 0.0300\n",
      "Epoch 115/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - val_loss: 0.0297\n",
      "Epoch 116/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0132 - val_loss: 0.0319\n",
      "Epoch 117/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0136 - val_loss: 0.0322\n",
      "Epoch 118/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - val_loss: 0.0327\n",
      "Epoch 119/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0140 - val_loss: 0.0338\n",
      "Epoch 120/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0132 - val_loss: 0.0333\n",
      "Epoch 121/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0142 - val_loss: 0.0314\n",
      "Epoch 122/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0133 - val_loss: 0.0317\n",
      "Epoch 123/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0320\n",
      "Epoch 124/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0131 - val_loss: 0.0304\n",
      "Epoch 125/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0131 - val_loss: 0.0302\n",
      "Epoch 126/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - val_loss: 0.0334\n",
      "Epoch 127/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0333\n",
      "Epoch 128/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: 0.0320\n",
      "Epoch 129/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0309\n",
      "Epoch 130/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0131 - val_loss: 0.0315\n",
      "Epoch 131/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - val_loss: 0.0327\n",
      "Epoch 132/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0127 - val_loss: 0.0323\n",
      "Epoch 133/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0131 - val_loss: 0.0334\n",
      "Epoch 134/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - val_loss: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0335\n",
      "Epoch 136/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0339\n",
      "Epoch 137/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0130 - val_loss: 0.0312\n",
      "Epoch 138/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0125 - val_loss: 0.0332\n",
      "Epoch 139/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0338\n",
      "Epoch 140/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0333\n",
      "Epoch 141/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0120 - val_loss: 0.0335\n",
      "Epoch 142/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0313\n",
      "Epoch 143/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0327\n",
      "Epoch 144/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0328\n",
      "Epoch 145/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0348\n",
      "Epoch 146/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0125 - val_loss: 0.0323\n",
      "Epoch 147/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0325\n",
      "Epoch 148/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0120 - val_loss: 0.0343\n",
      "Epoch 149/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - val_loss: 0.0341\n",
      "Epoch 150/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0116 - val_loss: 0.0319\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "paraguay, MAE: 152.52, MAPE: 0.027, R2: 0.950\n",
      "SVM Model - AIC: 36644.66, BIC: 36922.87\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 41/582\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.2634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8624 - val_loss: 0.0718\n",
      "Epoch 2/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8551 - val_loss: 0.0650\n",
      "Epoch 3/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2386 - val_loss: 0.0634\n",
      "Epoch 4/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2422 - val_loss: 0.0873\n",
      "Epoch 5/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4059 - val_loss: 0.0533\n",
      "Epoch 6/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2616 - val_loss: 0.0462\n",
      "Epoch 7/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1353 - val_loss: 0.0434\n",
      "Epoch 8/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1482 - val_loss: 0.0440\n",
      "Epoch 9/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0658 - val_loss: 0.0366\n",
      "Epoch 10/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0496 - val_loss: 0.0344\n",
      "Epoch 11/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1924 - val_loss: 0.0300\n",
      "Epoch 12/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5348 - val_loss: 0.0331\n",
      "Epoch 13/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0737 - val_loss: 0.0288\n",
      "Epoch 14/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0526 - val_loss: 0.0264\n",
      "Epoch 15/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.0249\n",
      "Epoch 16/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0211\n",
      "Epoch 17/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0219\n",
      "Epoch 18/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0184\n",
      "Epoch 19/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0452\n",
      "Epoch 20/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0722 - val_loss: 0.0180\n",
      "Epoch 21/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0189\n",
      "Epoch 22/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0199\n",
      "Epoch 23/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0174\n",
      "Epoch 24/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0152\n",
      "Epoch 25/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0150\n",
      "Epoch 26/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0347 - val_loss: 0.0222\n",
      "Epoch 27/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0536\n",
      "Epoch 28/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7453 - val_loss: 0.0374\n",
      "Epoch 29/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1645 - val_loss: 0.0322\n",
      "Epoch 30/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0767 - val_loss: 0.0340\n",
      "Epoch 31/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1848 - val_loss: 0.0310\n",
      "Epoch 32/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0695 - val_loss: 0.0259\n",
      "Epoch 33/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0822 - val_loss: 0.0266\n",
      "Epoch 34/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0668 - val_loss: 0.0189\n",
      "Epoch 35/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3778 - val_loss: 0.0210\n",
      "Epoch 36/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0782 - val_loss: 0.0261\n",
      "Epoch 37/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0731 - val_loss: 0.0173\n",
      "Epoch 38/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.0210\n",
      "Epoch 39/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0677 - val_loss: 0.0160\n",
      "Epoch 40/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.0167\n",
      "Epoch 41/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0295 - val_loss: 0.0168\n",
      "Epoch 42/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0158\n",
      "Epoch 43/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0163\n",
      "Epoch 44/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0151\n",
      "Epoch 45/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0150\n",
      "Epoch 46/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194 - val_loss: 0.0173\n",
      "Epoch 47/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.0146\n",
      "Epoch 48/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0132\n",
      "Epoch 49/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 50/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0481\n",
      "Epoch 51/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0998 - val_loss: 0.0174\n",
      "Epoch 52/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0901 - val_loss: 0.0171\n",
      "Epoch 53/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0150\n",
      "Epoch 54/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0158\n",
      "Epoch 55/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0150\n",
      "Epoch 56/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0146\n",
      "Epoch 57/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 58/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0137\n",
      "Epoch 59/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0167\n",
      "Epoch 60/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0653 - val_loss: 0.0484\n",
      "Epoch 61/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0204\n",
      "Epoch 62/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0180\n",
      "Epoch 63/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0889 - val_loss: 0.0303\n",
      "Epoch 64/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0730 - val_loss: 0.0178\n",
      "Epoch 65/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0443 - val_loss: 0.0157\n",
      "Epoch 66/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0732 - val_loss: 0.0144\n",
      "Epoch 67/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0468 - val_loss: 0.0153\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0532 - val_loss: 0.0156\n",
      "Epoch 69/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0920 - val_loss: 0.0145\n",
      "Epoch 70/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8474 - val_loss: 0.0898\n",
      "Epoch 71/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2549 - val_loss: 0.0413\n",
      "Epoch 72/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0894 - val_loss: 0.0361\n",
      "Epoch 73/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0946 - val_loss: 0.0301\n",
      "Epoch 74/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0824 - val_loss: 0.0241\n",
      "Epoch 75/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0708 - val_loss: 0.0245\n",
      "Epoch 76/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1031 - val_loss: 0.0218\n",
      "Epoch 77/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0484 - val_loss: 0.0180\n",
      "Epoch 78/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0990 - val_loss: 0.0202\n",
      "Epoch 79/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0616 - val_loss: 0.0189\n",
      "Epoch 80/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0163\n",
      "Epoch 81/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0162\n",
      "Epoch 82/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0161\n",
      "Epoch 83/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0154\n",
      "Epoch 84/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0156\n",
      "Epoch 85/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.0153\n",
      "Epoch 86/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0474 - val_loss: 0.0148\n",
      "Epoch 87/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0152\n",
      "Epoch 88/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0548 - val_loss: 0.0152\n",
      "Epoch 89/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0368 - val_loss: 0.0156\n",
      "Epoch 90/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0153\n",
      "Epoch 91/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0154\n",
      "Epoch 92/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0471 - val_loss: 0.0175\n",
      "Epoch 93/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0167\n",
      "Epoch 94/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0153\n",
      "Epoch 95/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0139\n",
      "Epoch 96/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0473 - val_loss: 0.0178\n",
      "Epoch 97/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2995 - val_loss: 0.0402\n",
      "Epoch 98/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1009 - val_loss: 0.0254\n",
      "Epoch 99/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1194 - val_loss: 0.0363\n",
      "Epoch 100/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1382 - val_loss: 0.0268\n",
      "Epoch 101/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0737 - val_loss: 0.0310\n",
      "Epoch 102/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0635 - val_loss: 0.0206\n",
      "Epoch 103/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0480 - val_loss: 0.0196\n",
      "Epoch 104/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0176\n",
      "Epoch 105/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0430 - val_loss: 0.0249\n",
      "Epoch 106/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0428 - val_loss: 0.0189\n",
      "Epoch 107/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0433 - val_loss: 0.0242\n",
      "Epoch 108/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0871 - val_loss: 0.0239\n",
      "Epoch 109/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.2727 - val_loss: 0.0268\n",
      "Epoch 110/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1064 - val_loss: 0.0254\n",
      "Epoch 111/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0534 - val_loss: 0.0362\n",
      "Epoch 112/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0887 - val_loss: 0.0239\n",
      "Epoch 113/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0223\n",
      "Epoch 114/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0507 - val_loss: 0.0214\n",
      "Epoch 115/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0429 - val_loss: 0.0195\n",
      "Epoch 116/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0233\n",
      "Epoch 117/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0332 - val_loss: 0.0216\n",
      "Epoch 118/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0392 - val_loss: 0.0186\n",
      "Epoch 119/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0173\n",
      "Epoch 120/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0182\n",
      "Epoch 121/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0499 - val_loss: 0.0181\n",
      "Epoch 122/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0739 - val_loss: 0.0200\n",
      "Epoch 123/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0683 - val_loss: 0.0205\n",
      "Epoch 124/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0160\n",
      "Epoch 125/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0180\n",
      "Epoch 126/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0479 - val_loss: 0.0181\n",
      "Epoch 127/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0526 - val_loss: 0.0164\n",
      "Epoch 128/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0207\n",
      "Epoch 129/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0633 - val_loss: 0.0160\n",
      "Epoch 130/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0155\n",
      "Epoch 131/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.0158\n",
      "Epoch 132/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0179\n",
      "Epoch 133/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0854 - val_loss: 0.0220\n",
      "Epoch 134/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0172\n",
      "Epoch 136/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0149\n",
      "Epoch 137/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0147\n",
      "Epoch 138/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0142\n",
      "Epoch 139/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0146\n",
      "Epoch 140/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0414 - val_loss: 0.0155\n",
      "Epoch 141/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0511 - val_loss: 0.0154\n",
      "Epoch 142/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0141\n",
      "Epoch 143/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0401 - val_loss: 0.0131\n",
      "Epoch 144/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0128\n",
      "Epoch 145/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0133\n",
      "Epoch 146/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0180\n",
      "Epoch 147/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0212\n",
      "Epoch 148/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3621 - val_loss: 0.0346\n",
      "Epoch 149/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0815 - val_loss: 0.0307\n",
      "Epoch 150/150\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2461 - val_loss: 0.0427\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "usa, MAE: 77999.86, MAPE: 0.050, R2: 0.925\n",
      "SVM Model - AIC: 77061.53, BIC: 77339.75\n",
      "Hyperparameters: lookback=24, n_layers=1\n",
      "Epoch 1/150\n",
      "\u001b[1m 42/102\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4969 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3258 - val_loss: 0.0453\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0651 - val_loss: 0.0406\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0429 - val_loss: 0.0411\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0304\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0204\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0294\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0206\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0182\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0162\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0146\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - val_loss: 0.0163\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - val_loss: 0.0176\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0234\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0084\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - val_loss: 0.0177\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0081\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 52/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 53/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 54/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 55/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 56/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 57/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 58/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 59/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 60/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 61/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 62/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0103\n",
      "Epoch 63/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 64/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 65/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 66/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 67/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0099\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 69/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 70/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 71/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0070\n",
      "Epoch 72/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 73/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 74/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 75/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 76/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 77/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 78/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 79/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 80/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 81/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 82/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0109\n",
      "Epoch 83/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 84/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 85/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 86/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 87/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 88/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 89/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - val_loss: 0.0069\n",
      "Epoch 90/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 91/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 92/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - val_loss: 0.0125\n",
      "Epoch 93/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: 0.0074\n",
      "Epoch 94/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 95/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 96/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 97/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 98/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 99/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 100/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 101/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 102/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 103/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 104/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 105/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 106/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 107/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 108/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 109/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 110/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 111/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 112/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 113/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 114/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0087\n",
      "Epoch 115/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0090\n",
      "Epoch 116/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0102\n",
      "Epoch 117/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0099\n",
      "Epoch 118/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 119/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 120/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 121/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 122/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 123/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 124/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 125/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 126/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 127/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 128/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 129/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 130/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 131/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 132/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0072\n",
      "Epoch 133/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0093\n",
      "Epoch 134/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 136/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0095\n",
      "Epoch 137/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0077\n",
      "Epoch 138/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 139/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 140/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 141/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 142/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 143/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 144/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 145/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 146/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 147/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 148/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0094\n",
      "Epoch 149/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 150/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "morocco, MAE: 6546.63, MAPE: 0.018, R2: 0.988\n",
      "SVM Model - AIC: 61013.67, BIC: 61314.60\n",
      "Epoch 1/150\n",
      "\u001b[1m 43/508\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 37.5136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5.6371 - val_loss: 0.1609\n",
      "Epoch 2/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1517 - val_loss: 0.0963\n",
      "Epoch 3/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0810 - val_loss: 0.0607\n",
      "Epoch 4/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0557 - val_loss: 0.0499\n",
      "Epoch 5/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0443 - val_loss: 0.0448\n",
      "Epoch 6/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0414 - val_loss: 0.0443\n",
      "Epoch 7/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0404 - val_loss: 0.0396\n",
      "Epoch 8/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.0409\n",
      "Epoch 9/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0412 - val_loss: 0.0414\n",
      "Epoch 10/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0376\n",
      "Epoch 11/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0337 - val_loss: 0.0413\n",
      "Epoch 12/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0372\n",
      "Epoch 13/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0353\n",
      "Epoch 14/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0365\n",
      "Epoch 15/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.0342\n",
      "Epoch 16/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0344\n",
      "Epoch 17/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0350\n",
      "Epoch 18/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0349 - val_loss: 0.0343\n",
      "Epoch 19/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0321\n",
      "Epoch 20/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0350\n",
      "Epoch 21/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0332\n",
      "Epoch 22/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0327\n",
      "Epoch 23/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0322\n",
      "Epoch 24/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.0325\n",
      "Epoch 25/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0317\n",
      "Epoch 26/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0329\n",
      "Epoch 27/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0274 - val_loss: 0.0330\n",
      "Epoch 28/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0319\n",
      "Epoch 29/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0274 - val_loss: 0.0347\n",
      "Epoch 30/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0313\n",
      "Epoch 31/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0315\n",
      "Epoch 32/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.0305\n",
      "Epoch 33/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0354\n",
      "Epoch 34/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0321\n",
      "Epoch 35/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0304\n",
      "Epoch 36/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0308\n",
      "Epoch 37/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0310\n",
      "Epoch 38/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0309\n",
      "Epoch 39/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0319\n",
      "Epoch 40/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0316\n",
      "Epoch 41/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0292\n",
      "Epoch 42/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0293\n",
      "Epoch 43/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0235 - val_loss: 0.0336\n",
      "Epoch 44/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0264 - val_loss: 0.0293\n",
      "Epoch 45/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0292\n",
      "Epoch 46/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0299\n",
      "Epoch 47/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0300\n",
      "Epoch 48/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0303\n",
      "Epoch 49/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0300\n",
      "Epoch 50/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0295\n",
      "Epoch 51/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0305\n",
      "Epoch 52/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0296\n",
      "Epoch 53/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0290\n",
      "Epoch 54/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0299\n",
      "Epoch 55/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0281\n",
      "Epoch 56/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0304\n",
      "Epoch 57/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0291\n",
      "Epoch 58/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0299\n",
      "Epoch 59/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0290\n",
      "Epoch 60/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0283\n",
      "Epoch 61/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0290\n",
      "Epoch 62/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0276\n",
      "Epoch 63/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0283\n",
      "Epoch 64/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0222 - val_loss: 0.0286\n",
      "Epoch 65/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0288\n",
      "Epoch 66/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0280\n",
      "Epoch 67/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0286\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0314\n",
      "Epoch 69/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0293\n",
      "Epoch 70/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0203 - val_loss: 0.0314\n",
      "Epoch 71/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0298\n",
      "Epoch 72/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0211 - val_loss: 0.0314\n",
      "Epoch 73/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0288\n",
      "Epoch 74/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0290\n",
      "Epoch 75/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0283\n",
      "Epoch 76/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0299\n",
      "Epoch 77/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0286\n",
      "Epoch 78/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0279\n",
      "Epoch 79/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0277\n",
      "Epoch 80/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0287\n",
      "Epoch 81/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0201 - val_loss: 0.0284\n",
      "Epoch 82/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0285\n",
      "Epoch 83/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0285\n",
      "Epoch 84/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0284\n",
      "Epoch 85/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0279\n",
      "Epoch 86/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0283\n",
      "Epoch 87/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0285\n",
      "Epoch 88/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0281\n",
      "Epoch 89/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0278\n",
      "Epoch 90/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0317\n",
      "Epoch 91/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0279\n",
      "Epoch 92/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0286\n",
      "Epoch 93/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0284\n",
      "Epoch 94/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0280\n",
      "Epoch 95/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0307\n",
      "Epoch 96/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0321\n",
      "Epoch 97/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0271\n",
      "Epoch 98/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0281\n",
      "Epoch 99/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0283\n",
      "Epoch 100/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0288\n",
      "Epoch 101/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0280\n",
      "Epoch 102/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0278\n",
      "Epoch 103/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0282\n",
      "Epoch 104/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0288\n",
      "Epoch 105/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0277\n",
      "Epoch 106/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0274\n",
      "Epoch 107/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0301\n",
      "Epoch 108/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0281\n",
      "Epoch 109/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0280\n",
      "Epoch 110/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0272\n",
      "Epoch 111/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0282\n",
      "Epoch 112/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0284\n",
      "Epoch 113/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0271\n",
      "Epoch 114/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0271\n",
      "Epoch 115/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0270\n",
      "Epoch 116/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0277\n",
      "Epoch 117/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0286\n",
      "Epoch 118/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0280\n",
      "Epoch 119/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0283\n",
      "Epoch 120/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0273\n",
      "Epoch 121/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0276\n",
      "Epoch 122/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0289\n",
      "Epoch 123/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0279\n",
      "Epoch 124/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0276\n",
      "Epoch 125/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0275\n",
      "Epoch 126/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0280\n",
      "Epoch 127/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0281\n",
      "Epoch 128/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0272\n",
      "Epoch 129/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0282\n",
      "Epoch 130/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0298\n",
      "Epoch 131/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0272\n",
      "Epoch 132/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0283\n",
      "Epoch 133/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0277\n",
      "Epoch 134/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0279\n",
      "Epoch 136/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0282\n",
      "Epoch 137/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0161 - val_loss: 0.0277\n",
      "Epoch 138/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0161 - val_loss: 0.0283\n",
      "Epoch 139/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0286\n",
      "Epoch 140/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0292\n",
      "Epoch 141/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0157 - val_loss: 0.0284\n",
      "Epoch 142/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0274\n",
      "Epoch 143/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0295\n",
      "Epoch 144/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0284\n",
      "Epoch 145/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159 - val_loss: 0.0279\n",
      "Epoch 146/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0160 - val_loss: 0.0278\n",
      "Epoch 147/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0290\n",
      "Epoch 148/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0277\n",
      "Epoch 149/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0279\n",
      "Epoch 150/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0279\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "paraguay, MAE: 143.62, MAPE: 0.025, R2: 0.956\n",
      "SVM Model - AIC: 36254.93, BIC: 36533.15\n",
      "Epoch 1/150\n",
      "\u001b[1m 42/581\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.2240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12.1078 - val_loss: 6.4971\n",
      "Epoch 2/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 113.1967 - val_loss: 0.9993\n",
      "Epoch 3/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5.0513 - val_loss: 0.1104\n",
      "Epoch 4/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.0313 - val_loss: 0.1251\n",
      "Epoch 5/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4264 - val_loss: 0.0981\n",
      "Epoch 6/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3787 - val_loss: 0.1051\n",
      "Epoch 7/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2237 - val_loss: 0.0752\n",
      "Epoch 8/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1726 - val_loss: 0.0659\n",
      "Epoch 9/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1220 - val_loss: 0.0610\n",
      "Epoch 10/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1183 - val_loss: 0.0517\n",
      "Epoch 11/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1096 - val_loss: 0.0498\n",
      "Epoch 12/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1042 - val_loss: 0.0722\n",
      "Epoch 13/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.1720 - val_loss: 0.0749\n",
      "Epoch 14/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2498 - val_loss: 0.1159\n",
      "Epoch 15/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1655 - val_loss: 0.0966\n",
      "Epoch 16/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2024 - val_loss: 0.0556\n",
      "Epoch 17/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2730 - val_loss: 0.0624\n",
      "Epoch 18/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1339 - val_loss: 0.0480\n",
      "Epoch 19/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1635 - val_loss: 0.0540\n",
      "Epoch 20/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1505 - val_loss: 0.0652\n",
      "Epoch 21/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1109 - val_loss: 0.0516\n",
      "Epoch 22/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0787 - val_loss: 0.0465\n",
      "Epoch 23/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0787 - val_loss: 0.0395\n",
      "Epoch 24/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0662 - val_loss: 0.0419\n",
      "Epoch 25/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1143 - val_loss: 0.0310\n",
      "Epoch 26/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0662 - val_loss: 0.0326\n",
      "Epoch 27/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0963 - val_loss: 0.0651\n",
      "Epoch 28/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.0793 - val_loss: 6.7025\n",
      "Epoch 29/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 11.4775 - val_loss: 0.6701\n",
      "Epoch 30/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3060 - val_loss: 0.2607\n",
      "Epoch 31/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6125 - val_loss: 0.2113\n",
      "Epoch 32/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6325 - val_loss: 0.1643\n",
      "Epoch 33/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3269 - val_loss: 0.3387\n",
      "Epoch 34/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.0719 - val_loss: 7.6879\n",
      "Epoch 35/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 83.6265 - val_loss: 5.9000\n",
      "Epoch 36/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 18.6555 - val_loss: 3.0314\n",
      "Epoch 37/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 13.3163 - val_loss: 1.3182\n",
      "Epoch 38/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.6928 - val_loss: 0.7411\n",
      "Epoch 39/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.6947 - val_loss: 0.6229\n",
      "Epoch 40/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.6304 - val_loss: 0.4710\n",
      "Epoch 41/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1938 - val_loss: 0.8383\n",
      "Epoch 42/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6410 - val_loss: 0.5274\n",
      "Epoch 43/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9566 - val_loss: 0.3209\n",
      "Epoch 44/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.6148 - val_loss: 0.2856\n",
      "Epoch 45/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6919 - val_loss: 0.2491\n",
      "Epoch 46/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4433 - val_loss: 0.2575\n",
      "Epoch 47/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8144 - val_loss: 0.3383\n",
      "Epoch 48/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.4161 - val_loss: 0.2323\n",
      "Epoch 49/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7512 - val_loss: 0.6199\n",
      "Epoch 50/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7776 - val_loss: 2.4036\n",
      "Epoch 51/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5755 - val_loss: 0.3363\n",
      "Epoch 52/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 22.1429 - val_loss: 1.8838\n",
      "Epoch 53/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.4825 - val_loss: 0.3036\n",
      "Epoch 54/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1129 - val_loss: 0.2608\n",
      "Epoch 55/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7162 - val_loss: 1.4679\n",
      "Epoch 56/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 65.9411 - val_loss: 4.5996\n",
      "Epoch 57/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5.2867 - val_loss: 1.6889\n",
      "Epoch 58/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.8508 - val_loss: 1.4343\n",
      "Epoch 59/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9263 - val_loss: 0.8210\n",
      "Epoch 60/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.1584 - val_loss: 1.2973\n",
      "Epoch 61/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.5203 - val_loss: 0.8432\n",
      "Epoch 62/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.0412 - val_loss: 0.9823\n",
      "Epoch 63/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.7337 - val_loss: 0.6678\n",
      "Epoch 64/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.6640 - val_loss: 0.5630\n",
      "Epoch 65/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7474 - val_loss: 0.6196\n",
      "Epoch 66/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9016 - val_loss: 0.4525\n",
      "Epoch 67/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7963 - val_loss: 0.5557\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5.7715 - val_loss: 0.5292\n",
      "Epoch 69/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7462 - val_loss: 0.5719\n",
      "Epoch 70/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9775 - val_loss: 0.4612\n",
      "Epoch 71/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8506 - val_loss: 0.4783\n",
      "Epoch 72/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7352 - val_loss: 0.5147\n",
      "Epoch 73/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.6662 - val_loss: 1.4683\n",
      "Epoch 74/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 64.6901 - val_loss: 11.2867\n",
      "Epoch 75/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 54.6785 - val_loss: 0.8041\n",
      "Epoch 76/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9751 - val_loss: 0.7414\n",
      "Epoch 77/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9929 - val_loss: 8.3330\n",
      "Epoch 78/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.9012 - val_loss: 0.8259\n",
      "Epoch 79/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.4827 - val_loss: 0.5952\n",
      "Epoch 80/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9300 - val_loss: 0.4937\n",
      "Epoch 81/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9326 - val_loss: 3.9327\n",
      "Epoch 82/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.8259 - val_loss: 0.7245\n",
      "Epoch 83/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.2700 - val_loss: 0.3625\n",
      "Epoch 84/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.5817 - val_loss: 0.4488\n",
      "Epoch 85/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.1547 - val_loss: 0.3913\n",
      "Epoch 86/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5.1670 - val_loss: 0.5601\n",
      "Epoch 87/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 14.0823 - val_loss: 0.5841\n",
      "Epoch 88/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8387 - val_loss: 0.5455\n",
      "Epoch 89/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3376 - val_loss: 2.2668\n",
      "Epoch 90/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.2241 - val_loss: 0.9200\n",
      "Epoch 91/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.4791 - val_loss: 0.6819\n",
      "Epoch 92/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9038 - val_loss: 1.9417\n",
      "Epoch 93/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.9783 - val_loss: 0.9885\n",
      "Epoch 94/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 61.8159 - val_loss: 0.6101\n",
      "Epoch 95/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1052 - val_loss: 0.5628\n",
      "Epoch 96/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7624 - val_loss: 0.5410\n",
      "Epoch 97/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7820 - val_loss: 0.5646\n",
      "Epoch 98/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1198 - val_loss: 0.4711\n",
      "Epoch 99/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6884 - val_loss: 0.6552\n",
      "Epoch 100/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.1290 - val_loss: 1.6751\n",
      "Epoch 101/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 14.9259 - val_loss: 0.9792\n",
      "Epoch 102/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 107.9064 - val_loss: 2.1943\n",
      "Epoch 103/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.7201 - val_loss: 0.9910\n",
      "Epoch 104/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.7556 - val_loss: 0.5138\n",
      "Epoch 105/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1170 - val_loss: 0.4727\n",
      "Epoch 106/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1121 - val_loss: 0.5364\n",
      "Epoch 107/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.6222 - val_loss: 0.6697\n",
      "Epoch 108/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12.9983 - val_loss: 0.4606\n",
      "Epoch 109/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.9483 - val_loss: 0.4251\n",
      "Epoch 110/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1462 - val_loss: 1.6353\n",
      "Epoch 111/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 314.6427 - val_loss: 0.5170\n",
      "Epoch 112/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.4552 - val_loss: 0.5935\n",
      "Epoch 113/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9590 - val_loss: 0.4964\n",
      "Epoch 114/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.1617 - val_loss: 141.5953\n",
      "Epoch 115/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4353.3672 - val_loss: 269.0098\n",
      "Epoch 116/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 329.0408 - val_loss: 6.3775\n",
      "Epoch 117/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 26.9823 - val_loss: 1.7586\n",
      "Epoch 118/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.9991 - val_loss: 1.8443\n",
      "Epoch 119/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 59.4909 - val_loss: 61.9990\n",
      "Epoch 120/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 756.7816 - val_loss: 132.4082\n",
      "Epoch 121/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 597.7529 - val_loss: 951.8865\n",
      "Epoch 122/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 11707.2227 - val_loss: 34155.6562\n",
      "Epoch 123/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 16916.3203 - val_loss: 16.2553\n",
      "Epoch 124/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12.2609 - val_loss: 2.7649\n",
      "Epoch 125/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 31.7145 - val_loss: 6.3021\n",
      "Epoch 126/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 254.5641 - val_loss: 0.8895\n",
      "Epoch 127/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10412.5566 - val_loss: 79.9491\n",
      "Epoch 128/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 44.9370 - val_loss: 4.1085\n",
      "Epoch 129/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 228.4394 - val_loss: 3.3003\n",
      "Epoch 130/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 31.0022 - val_loss: 0.6385\n",
      "Epoch 131/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 39.4480 - val_loss: 3.7389\n",
      "Epoch 132/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5680.6108 - val_loss: 3778.3037\n",
      "Epoch 133/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2588.8330 - val_loss: 162.2184\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 120.2540 - val_loss: 16.5237\n",
      "Epoch 135/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 34.8391 - val_loss: 9.6918\n",
      "Epoch 136/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 21.1352 - val_loss: 1.3311\n",
      "Epoch 137/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.2853 - val_loss: 1.3125\n",
      "Epoch 138/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8.5693 - val_loss: 137.1318\n",
      "Epoch 139/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 108.4583 - val_loss: 1.5173\n",
      "Epoch 140/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8.6909 - val_loss: 1.2740\n",
      "Epoch 141/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 14.7798 - val_loss: 13.6889\n",
      "Epoch 142/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10.6372 - val_loss: 2.5568\n",
      "Epoch 143/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.3938 - val_loss: 4.7487\n",
      "Epoch 144/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 110.9020 - val_loss: 3.9405\n",
      "Epoch 145/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 740.3276 - val_loss: 6.0850\n",
      "Epoch 146/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 349.2093 - val_loss: 6.0390\n",
      "Epoch 147/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 11.0224 - val_loss: 1.9090\n",
      "Epoch 148/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 38.0225 - val_loss: 1.0452\n",
      "Epoch 149/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.5445 - val_loss: 1.4207\n",
      "Epoch 150/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.0186 - val_loss: 1.2237\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "usa, MAE: 412890.63, MAPE: 0.291, R2: -1.156\n",
      "SVM Model - AIC: 87860.29, BIC: 88138.51\n",
      "Hyperparameters: lookback=24, n_layers=2\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 22/102\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7279  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3994 - val_loss: 0.0777\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0864 - val_loss: 0.0399\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0784 - val_loss: 0.0485\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0532 - val_loss: 0.0519\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0452 - val_loss: 0.0335\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0392 - val_loss: 0.0258\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - val_loss: 0.0453\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0348 - val_loss: 0.0211\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0291 - val_loss: 0.0208\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0279 - val_loss: 0.0256\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0231 - val_loss: 0.0348\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0237 - val_loss: 0.0188\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0230 - val_loss: 0.0189\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0263 - val_loss: 0.0221\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187 - val_loss: 0.0346\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0241 - val_loss: 0.0152\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0175 - val_loss: 0.0168\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175 - val_loss: 0.0284\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.0243\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0265 - val_loss: 0.0120\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.0112\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0131 - val_loss: 0.0191\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.0136\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 52/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 53/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 54/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0100\n",
      "Epoch 55/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 56/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 57/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 58/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 59/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 60/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 61/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 62/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 63/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 64/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 65/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 66/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 67/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 69/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 70/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 71/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 72/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 73/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 74/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 75/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 76/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 77/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 78/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 79/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 80/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 81/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 82/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 83/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 84/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0086\n",
      "Epoch 85/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 86/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 87/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 88/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 89/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 90/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 91/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 92/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 93/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 94/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0084\n",
      "Epoch 95/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 96/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 97/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 98/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 99/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 100/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 101/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 102/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 103/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 104/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 105/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 106/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 107/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0086\n",
      "Epoch 108/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0138\n",
      "Epoch 109/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 110/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 111/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 112/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 113/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 114/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 115/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0075\n",
      "Epoch 116/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0094\n",
      "Epoch 117/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 118/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 119/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 120/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0099\n",
      "Epoch 121/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 122/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 123/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 124/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0089\n",
      "Epoch 125/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 126/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 127/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0071\n",
      "Epoch 128/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0078\n",
      "Epoch 129/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0096\n",
      "Epoch 130/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 131/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0092\n",
      "Epoch 132/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 133/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 134/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 136/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 137/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 138/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 139/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 140/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 141/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0103\n",
      "Epoch 142/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 143/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 144/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0080\n",
      "Epoch 145/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0089\n",
      "Epoch 146/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0083\n",
      "Epoch 147/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0078\n",
      "Epoch 148/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0087\n",
      "Epoch 149/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0101\n",
      "Epoch 150/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0106\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "morocco, MAE: 7844.13, MAPE: 0.021, R2: 0.983\n",
      "SVM Model - AIC: 62185.35, BIC: 62486.27\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 24/508\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.8621  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.4341 - val_loss: 0.1453\n",
      "Epoch 2/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1198 - val_loss: 0.0799\n",
      "Epoch 3/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0686 - val_loss: 0.0544\n",
      "Epoch 4/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0491 - val_loss: 0.0457\n",
      "Epoch 5/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0449 - val_loss: 0.0433\n",
      "Epoch 6/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0381 - val_loss: 0.0373\n",
      "Epoch 7/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0368 - val_loss: 0.0354\n",
      "Epoch 8/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0360 - val_loss: 0.0397\n",
      "Epoch 9/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0335 - val_loss: 0.0370\n",
      "Epoch 10/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0325 - val_loss: 0.0330\n",
      "Epoch 11/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0332\n",
      "Epoch 12/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0310 - val_loss: 0.0335\n",
      "Epoch 13/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0304 - val_loss: 0.0323\n",
      "Epoch 14/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0292 - val_loss: 0.0535\n",
      "Epoch 15/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0421 - val_loss: 0.0308\n",
      "Epoch 16/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0298 - val_loss: 0.0303\n",
      "Epoch 17/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0302 - val_loss: 0.0320\n",
      "Epoch 18/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0290 - val_loss: 0.0327\n",
      "Epoch 19/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0281 - val_loss: 0.0291\n",
      "Epoch 20/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0267 - val_loss: 0.0301\n",
      "Epoch 21/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0297 - val_loss: 0.0309\n",
      "Epoch 22/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0308\n",
      "Epoch 23/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0291 - val_loss: 0.0294\n",
      "Epoch 24/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0264 - val_loss: 0.0324\n",
      "Epoch 25/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0267 - val_loss: 0.0282\n",
      "Epoch 26/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0253 - val_loss: 0.0294\n",
      "Epoch 27/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0251 - val_loss: 0.0289\n",
      "Epoch 28/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0247 - val_loss: 0.0306\n",
      "Epoch 29/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0240 - val_loss: 0.0386\n",
      "Epoch 30/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0256 - val_loss: 0.0287\n",
      "Epoch 31/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0270 - val_loss: 0.0278\n",
      "Epoch 32/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0234 - val_loss: 0.0293\n",
      "Epoch 33/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0247 - val_loss: 0.0300\n",
      "Epoch 34/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0241 - val_loss: 0.0285\n",
      "Epoch 35/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0227 - val_loss: 0.0317\n",
      "Epoch 36/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0241 - val_loss: 0.0276\n",
      "Epoch 37/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0288\n",
      "Epoch 38/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0235 - val_loss: 0.0283\n",
      "Epoch 39/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0234 - val_loss: 0.0305\n",
      "Epoch 40/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0233 - val_loss: 0.0278\n",
      "Epoch 41/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0229 - val_loss: 0.0285\n",
      "Epoch 42/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0219 - val_loss: 0.0270\n",
      "Epoch 43/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0232 - val_loss: 0.0325\n",
      "Epoch 44/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0221 - val_loss: 0.0272\n",
      "Epoch 45/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.0269\n",
      "Epoch 46/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0215 - val_loss: 0.0368\n",
      "Epoch 47/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0227 - val_loss: 0.0258\n",
      "Epoch 48/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0203 - val_loss: 0.0260\n",
      "Epoch 49/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0211 - val_loss: 0.0274\n",
      "Epoch 50/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0213 - val_loss: 0.0270\n",
      "Epoch 51/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0200 - val_loss: 0.0290\n",
      "Epoch 52/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 53/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0210 - val_loss: 0.0278\n",
      "Epoch 54/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0206 - val_loss: 0.0258\n",
      "Epoch 55/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0205 - val_loss: 0.0299\n",
      "Epoch 56/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0221 - val_loss: 0.0286\n",
      "Epoch 57/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0200 - val_loss: 0.0290\n",
      "Epoch 58/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.0291\n",
      "Epoch 59/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.0276\n",
      "Epoch 60/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0193 - val_loss: 0.0283\n",
      "Epoch 61/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0203 - val_loss: 0.0274\n",
      "Epoch 62/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0194 - val_loss: 0.0272\n",
      "Epoch 63/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0188 - val_loss: 0.0278\n",
      "Epoch 64/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0187 - val_loss: 0.0316\n",
      "Epoch 65/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: 0.0288\n",
      "Epoch 66/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0197 - val_loss: 0.0278\n",
      "Epoch 67/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0188 - val_loss: 0.0278\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0185 - val_loss: 0.0296\n",
      "Epoch 69/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0193 - val_loss: 0.0292\n",
      "Epoch 70/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183 - val_loss: 0.0273\n",
      "Epoch 71/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0186 - val_loss: 0.0282\n",
      "Epoch 72/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0187 - val_loss: 0.0288\n",
      "Epoch 73/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0176 - val_loss: 0.0304\n",
      "Epoch 74/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.0314\n",
      "Epoch 75/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0172 - val_loss: 0.0291\n",
      "Epoch 76/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0174 - val_loss: 0.0284\n",
      "Epoch 77/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0173 - val_loss: 0.0292\n",
      "Epoch 78/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.0284\n",
      "Epoch 79/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0164 - val_loss: 0.0298\n",
      "Epoch 80/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0172 - val_loss: 0.0287\n",
      "Epoch 81/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0174 - val_loss: 0.0289\n",
      "Epoch 82/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0166 - val_loss: 0.0349\n",
      "Epoch 83/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0179 - val_loss: 0.0292\n",
      "Epoch 84/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0170 - val_loss: 0.0288\n",
      "Epoch 85/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0168 - val_loss: 0.0312\n",
      "Epoch 86/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0169 - val_loss: 0.0291\n",
      "Epoch 87/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0171 - val_loss: 0.0309\n",
      "Epoch 88/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0167 - val_loss: 0.0300\n",
      "Epoch 89/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0167 - val_loss: 0.0308\n",
      "Epoch 90/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0171 - val_loss: 0.0306\n",
      "Epoch 91/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0192 - val_loss: 0.0290\n",
      "Epoch 92/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0161 - val_loss: 0.0283\n",
      "Epoch 93/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0280\n",
      "Epoch 94/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0285\n",
      "Epoch 95/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.0298\n",
      "Epoch 96/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0158 - val_loss: 0.0300\n",
      "Epoch 97/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0158 - val_loss: 0.0273\n",
      "Epoch 98/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0166 - val_loss: 0.0285\n",
      "Epoch 99/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0154 - val_loss: 0.0316\n",
      "Epoch 100/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0157 - val_loss: 0.0296\n",
      "Epoch 101/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0156 - val_loss: 0.0299\n",
      "Epoch 102/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0297\n",
      "Epoch 103/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0145 - val_loss: 0.0304\n",
      "Epoch 104/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0153 - val_loss: 0.0282\n",
      "Epoch 105/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0151 - val_loss: 0.0299\n",
      "Epoch 106/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.0313\n",
      "Epoch 107/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.0299\n",
      "Epoch 108/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0147 - val_loss: 0.0287\n",
      "Epoch 109/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.0309\n",
      "Epoch 110/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0149 - val_loss: 0.0295\n",
      "Epoch 111/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0149 - val_loss: 0.0288\n",
      "Epoch 112/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0145 - val_loss: 0.0287\n",
      "Epoch 113/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0151 - val_loss: 0.0294\n",
      "Epoch 114/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.0295\n",
      "Epoch 115/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0153 - val_loss: 0.0296\n",
      "Epoch 116/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0140 - val_loss: 0.0297\n",
      "Epoch 117/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.0299\n",
      "Epoch 118/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.0303\n",
      "Epoch 119/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0146 - val_loss: 0.0331\n",
      "Epoch 120/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0145 - val_loss: 0.0319\n",
      "Epoch 121/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0141 - val_loss: 0.0304\n",
      "Epoch 122/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0138 - val_loss: 0.0324\n",
      "Epoch 123/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0139 - val_loss: 0.0330\n",
      "Epoch 124/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0140 - val_loss: 0.0306\n",
      "Epoch 125/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.0292\n",
      "Epoch 126/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.0330\n",
      "Epoch 127/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.0292\n",
      "Epoch 128/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0135 - val_loss: 0.0308\n",
      "Epoch 129/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 0.0304\n",
      "Epoch 130/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.0300\n",
      "Epoch 131/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0128 - val_loss: 0.0321\n",
      "Epoch 132/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.0311\n",
      "Epoch 133/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.0360\n",
      "Epoch 134/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0138 - val_loss: 0.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0131 - val_loss: 0.0313\n",
      "Epoch 136/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0138 - val_loss: 0.0318\n",
      "Epoch 137/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0136 - val_loss: 0.0325\n",
      "Epoch 138/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0317\n",
      "Epoch 139/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.0342\n",
      "Epoch 140/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.0311\n",
      "Epoch 141/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.0312\n",
      "Epoch 142/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.0338\n",
      "Epoch 143/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0336\n",
      "Epoch 144/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.0312\n",
      "Epoch 145/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.0323\n",
      "Epoch 146/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.0320\n",
      "Epoch 147/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0310\n",
      "Epoch 148/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.0337\n",
      "Epoch 149/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.0344\n",
      "Epoch 150/150\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0125 - val_loss: 0.0357\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "paraguay, MAE: 155.67, MAPE: 0.027, R2: 0.943\n",
      "SVM Model - AIC: 36777.01, BIC: 37055.23\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 24/581\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4078  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 5.3771 - val_loss: 0.1198\n",
      "Epoch 2/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3722 - val_loss: 0.0911\n",
      "Epoch 3/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 10.9028 - val_loss: 0.1734\n",
      "Epoch 4/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4083 - val_loss: 0.0525\n",
      "Epoch 5/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1703 - val_loss: 0.0432\n",
      "Epoch 6/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1415 - val_loss: 0.0429\n",
      "Epoch 7/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4971 - val_loss: 0.0527\n",
      "Epoch 8/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3159 - val_loss: 0.0434\n",
      "Epoch 9/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1332 - val_loss: 0.0349\n",
      "Epoch 10/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0496 - val_loss: 0.0307\n",
      "Epoch 11/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0658 - val_loss: 0.0265\n",
      "Epoch 12/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2702 - val_loss: 0.0372\n",
      "Epoch 13/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4216 - val_loss: 0.0285\n",
      "Epoch 14/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0911 - val_loss: 0.0309\n",
      "Epoch 15/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0921 - val_loss: 0.0292\n",
      "Epoch 16/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.7593 - val_loss: 0.1147\n",
      "Epoch 17/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 11.0905 - val_loss: 1.6170\n",
      "Epoch 18/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 9.8785 - val_loss: 0.5092\n",
      "Epoch 19/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 7.5228 - val_loss: 2.8339\n",
      "Epoch 20/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2.9451 - val_loss: 0.2061\n",
      "Epoch 21/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.1842 - val_loss: 2.6065\n",
      "Epoch 22/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.2880 - val_loss: 0.3480\n",
      "Epoch 23/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 10.3664 - val_loss: 4.2274\n",
      "Epoch 24/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 15.9964 - val_loss: 0.1667\n",
      "Epoch 25/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.9004 - val_loss: 0.1230\n",
      "Epoch 26/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5577 - val_loss: 0.1155\n",
      "Epoch 27/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4290 - val_loss: 0.1111\n",
      "Epoch 28/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4215 - val_loss: 0.1145\n",
      "Epoch 29/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.2472 - val_loss: 0.1059\n",
      "Epoch 30/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.3938 - val_loss: 0.1262\n",
      "Epoch 31/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.6882 - val_loss: 0.1310\n",
      "Epoch 32/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.4297 - val_loss: 0.0932\n",
      "Epoch 33/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.2104 - val_loss: 0.0918\n",
      "Epoch 34/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2154 - val_loss: 0.2275\n",
      "Epoch 35/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.4796 - val_loss: 0.0858\n",
      "Epoch 36/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.8048 - val_loss: 18.5279\n",
      "Epoch 37/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 7521.1592 - val_loss: 2.1299\n",
      "Epoch 38/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2.2758 - val_loss: 0.7308\n",
      "Epoch 39/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.2182 - val_loss: 0.6650\n",
      "Epoch 40/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.2257 - val_loss: 1.0988\n",
      "Epoch 41/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.7926 - val_loss: 0.6705\n",
      "Epoch 42/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2280.6782 - val_loss: 1629.6006\n",
      "Epoch 43/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1213.7683 - val_loss: 950.2819\n",
      "Epoch 44/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 763.4946 - val_loss: 24.8772\n",
      "Epoch 45/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 74.4732 - val_loss: 7.8205\n",
      "Epoch 46/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 21.9803 - val_loss: 3.2992\n",
      "Epoch 47/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 25.0355 - val_loss: 11.3656\n",
      "Epoch 48/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 7.9467 - val_loss: 4.1138\n",
      "Epoch 49/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 12.4836 - val_loss: 1.6902\n",
      "Epoch 50/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 5.2898 - val_loss: 6.7233\n",
      "Epoch 51/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 3.1483 - val_loss: 1.6792\n",
      "Epoch 52/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.6051 - val_loss: 0.9003\n",
      "Epoch 53/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.0996 - val_loss: 0.6700\n",
      "Epoch 54/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.9012 - val_loss: 0.5866\n",
      "Epoch 55/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.0277 - val_loss: 6.0484\n",
      "Epoch 56/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 30.7055 - val_loss: 60.4488\n",
      "Epoch 57/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 56.1683 - val_loss: 1.9498\n",
      "Epoch 58/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.7175 - val_loss: 0.8132\n",
      "Epoch 59/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 707.1967 - val_loss: 375.6057\n",
      "Epoch 60/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 85.9331 - val_loss: 17.5743\n",
      "Epoch 61/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 25.5612 - val_loss: 2.6216\n",
      "Epoch 62/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 27.8063 - val_loss: 4.7878\n",
      "Epoch 63/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.8607 - val_loss: 0.8419\n",
      "Epoch 64/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.9148 - val_loss: 0.5112\n",
      "Epoch 65/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.7900 - val_loss: 0.6852\n",
      "Epoch 66/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 5.5018 - val_loss: 0.5153\n",
      "Epoch 67/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.7258 - val_loss: 0.5487\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.6158 - val_loss: 0.5481\n",
      "Epoch 69/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.9781 - val_loss: 1.2433\n",
      "Epoch 70/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 18.3212 - val_loss: 1.5121\n",
      "Epoch 71/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 4.8327 - val_loss: 0.6474\n",
      "Epoch 72/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.7739 - val_loss: 0.4905\n",
      "Epoch 73/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6995 - val_loss: 0.5205\n",
      "Epoch 74/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 4.6734 - val_loss: 0.3923\n",
      "Epoch 75/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.9235 - val_loss: 0.5251\n",
      "Epoch 76/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.9300 - val_loss: 0.5332\n",
      "Epoch 77/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.9530 - val_loss: 0.3264\n",
      "Epoch 78/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 3.1362 - val_loss: 0.3583\n",
      "Epoch 79/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4078 - val_loss: 0.3613\n",
      "Epoch 80/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4427 - val_loss: 0.3293\n",
      "Epoch 81/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4727 - val_loss: 0.3130\n",
      "Epoch 82/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 368.5979 - val_loss: 0.3546\n",
      "Epoch 83/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 7.6966 - val_loss: 0.5456\n",
      "Epoch 84/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4821 - val_loss: 0.3146\n",
      "Epoch 85/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.6677 - val_loss: 0.3045\n",
      "Epoch 86/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5346 - val_loss: 0.2967\n",
      "Epoch 87/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4192 - val_loss: 0.2799\n",
      "Epoch 88/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4343 - val_loss: 0.2338\n",
      "Epoch 89/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3194 - val_loss: 0.2174\n",
      "Epoch 90/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3725 - val_loss: 0.1792\n",
      "Epoch 91/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2953 - val_loss: 0.1666\n",
      "Epoch 92/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4597 - val_loss: 0.1667\n",
      "Epoch 93/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2811 - val_loss: 0.2486\n",
      "Epoch 94/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3314 - val_loss: 0.1645\n",
      "Epoch 95/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4010 - val_loss: 0.1468\n",
      "Epoch 96/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2871 - val_loss: 0.2204\n",
      "Epoch 97/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.3532 - val_loss: 0.2058\n",
      "Epoch 98/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2818 - val_loss: 0.2303\n",
      "Epoch 99/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5049 - val_loss: 0.2117\n",
      "Epoch 100/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3909 - val_loss: 0.1590\n",
      "Epoch 101/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2628 - val_loss: 0.1563\n",
      "Epoch 102/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2286 - val_loss: 0.1525\n",
      "Epoch 103/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 12.2830 - val_loss: 0.3761\n",
      "Epoch 104/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.6162 - val_loss: 0.2789\n",
      "Epoch 105/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3435 - val_loss: 0.1953\n",
      "Epoch 106/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4204 - val_loss: 0.2000\n",
      "Epoch 107/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2639 - val_loss: 0.1401\n",
      "Epoch 108/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2454 - val_loss: 0.1423\n",
      "Epoch 109/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2643 - val_loss: 0.1069\n",
      "Epoch 110/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2235 - val_loss: 0.1096\n",
      "Epoch 111/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3024 - val_loss: 0.1185\n",
      "Epoch 112/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2471 - val_loss: 0.1017\n",
      "Epoch 113/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2219 - val_loss: 0.1641\n",
      "Epoch 114/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1706 - val_loss: 0.1930\n",
      "Epoch 115/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.8136 - val_loss: 0.1184\n",
      "Epoch 116/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4030 - val_loss: 0.1143\n",
      "Epoch 117/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 15.8103 - val_loss: 0.1288\n",
      "Epoch 118/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2243 - val_loss: 0.1288\n",
      "Epoch 119/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2450 - val_loss: 0.1017\n",
      "Epoch 120/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2976 - val_loss: 0.1065\n",
      "Epoch 121/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5446 - val_loss: 0.0956\n",
      "Epoch 122/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2514 - val_loss: 0.1066\n",
      "Epoch 123/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3018 - val_loss: 0.0952\n",
      "Epoch 124/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2089 - val_loss: 0.1057\n",
      "Epoch 125/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2643 - val_loss: 0.0914\n",
      "Epoch 126/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1969 - val_loss: 0.1141\n",
      "Epoch 127/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2220 - val_loss: 0.1083\n",
      "Epoch 128/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2062 - val_loss: 0.1192\n",
      "Epoch 129/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1859 - val_loss: 0.1607\n",
      "Epoch 130/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.6067 - val_loss: 0.2699\n",
      "Epoch 131/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5689 - val_loss: 0.1571\n",
      "Epoch 132/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.7334 - val_loss: 0.1947\n",
      "Epoch 133/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4693 - val_loss: 0.1563\n",
      "Epoch 134/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2602 - val_loss: 0.1286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5485 - val_loss: 0.1062\n",
      "Epoch 136/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2570 - val_loss: 0.1325\n",
      "Epoch 137/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2484 - val_loss: 0.1184\n",
      "Epoch 138/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2071 - val_loss: 0.1264\n",
      "Epoch 139/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3054 - val_loss: 0.1906\n",
      "Epoch 140/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4172 - val_loss: 0.1370\n",
      "Epoch 141/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3099 - val_loss: 0.1669\n",
      "Epoch 142/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.8935 - val_loss: 0.3296\n",
      "Epoch 143/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.1193 - val_loss: 0.2650\n",
      "Epoch 144/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 5.9633 - val_loss: 0.4006\n",
      "Epoch 145/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.3200 - val_loss: 0.3304\n",
      "Epoch 146/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.1698 - val_loss: 0.4862\n",
      "Epoch 147/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.6113 - val_loss: 0.3899\n",
      "Epoch 148/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.7446 - val_loss: 0.3369\n",
      "Epoch 149/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5319 - val_loss: 0.2930\n",
      "Epoch 150/150\n",
      "\u001b[1m581/581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.7609 - val_loss: 0.2705\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "usa, MAE: 195332.06, MAPE: 0.134, R2: 0.524\n",
      "SVM Model - AIC: 83010.13, BIC: 83288.35\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.12/site-packages/pandas/plotting/_core.py:1193\u001b[0m, in \u001b[0;36mPlotAccessor.bar\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, y: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1183\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PlotAccessor:\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;124;03m    Vertical bar plot.\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    other axis represents a measured value.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.12/site-packages/pandas/plotting/_core.py:1031\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1029\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[0;32m-> 1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_backend\u001b[38;5;241m.\u001b[39mplot(data, kind\u001b[38;5;241m=\u001b[39mkind, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.12/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mgenerate()\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.12/site-packages/pandas/plotting/_matplotlib/core.py:451\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_adjust()\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_plot_data()\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_subplots()\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot()\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.12/site-packages/pandas/plotting/_matplotlib/core.py:636\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[0;32m--> 636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning done on 50 epochs 48 lagged steps\n",
    "hyperparameter_tuning = {}\n",
    "for lookback in [6, 12, 24]:\n",
    "    for n_layers in [1, 2]:\n",
    "        print(f'Hyperparameters: lookback={lookback}, n_layers={n_layers}')\n",
    "        parameter_results = []\n",
    "        for dataset_name in datasets_electricity:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            data = add_lagged_timesteps(datasets[dataset_name], lag_periods=[i for i in range(1, 49)], lagged_feature='Consumption').dropna().reset_index(drop=True)\n",
    "            r2, mae, mape, aic_value, bic_value = lstm_fitting_and_evaluation(data.drop(columns=['DateTime', 'Consumption', 'Temperature']), data['Consumption'], dataset_name, model_file_identifier=str(lookback) + \"_\" + str(n_layers), lookback=lookback, n_layers=n_layers)\n",
    "            parameter_results.append(aic_value)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "            \n",
    "        hyperparameter_tuning[\"Lookback:\"+str(lookback) + ' ' + \"Layers:\"+str(n_layers)] = parameter_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e08db2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created.\n"
     ]
    }
   ],
   "source": [
    "# Save the tuning data\n",
    "columns = ['R2', 'MAE', 'MAPE', 'AIC', 'BIC']\n",
    "index = ['morocco', 'paraguay', 'usa']\n",
    "data_frames = {key: pd.DataFrame(hyperparameter_tuning[key], columns=columns, index=index) for key in hyperparameter_tuning}\n",
    "\n",
    "# Combine all the data into one DataFrame\n",
    "df_all = pd.concat(data_frames, axis=1)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_all.to_csv(\"hyperparameter_tuning_results.csv\")\n",
    "print(\"CSV file has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b52d1e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Lookback:6 Layers:1</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Lookback:6 Layers:2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Lookback:24 Layers:1</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Lookback:24 Layers:2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>...</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>morocco</th>\n",
       "      <td>0.982164</td>\n",
       "      <td>8027.250595</td>\n",
       "      <td>0.022421</td>\n",
       "      <td>62334.885335</td>\n",
       "      <td>62635.812101</td>\n",
       "      <td>0.982147</td>\n",
       "      <td>8240.161112</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>62504.517598</td>\n",
       "      <td>62805.444364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987972</td>\n",
       "      <td>6546.634698</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>61013.672001</td>\n",
       "      <td>61314.598766</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>7844.128786</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>62185.347988</td>\n",
       "      <td>62486.274753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paraguay</th>\n",
       "      <td>0.950593</td>\n",
       "      <td>146.690288</td>\n",
       "      <td>0.025836</td>\n",
       "      <td>36392.150629</td>\n",
       "      <td>36670.365940</td>\n",
       "      <td>0.948501</td>\n",
       "      <td>155.398985</td>\n",
       "      <td>0.027083</td>\n",
       "      <td>36765.867929</td>\n",
       "      <td>37044.083241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956036</td>\n",
       "      <td>143.616675</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>36254.932022</td>\n",
       "      <td>36533.147333</td>\n",
       "      <td>0.943414</td>\n",
       "      <td>155.666450</td>\n",
       "      <td>0.027250</td>\n",
       "      <td>36777.011405</td>\n",
       "      <td>37055.226717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usa</th>\n",
       "      <td>0.980308</td>\n",
       "      <td>38775.828662</td>\n",
       "      <td>0.024746</td>\n",
       "      <td>72532.593749</td>\n",
       "      <td>72810.809060</td>\n",
       "      <td>0.979747</td>\n",
       "      <td>39507.751625</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>72653.768559</td>\n",
       "      <td>72931.983871</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.156424</td>\n",
       "      <td>412890.634409</td>\n",
       "      <td>0.290683</td>\n",
       "      <td>87860.292892</td>\n",
       "      <td>88138.508204</td>\n",
       "      <td>0.523606</td>\n",
       "      <td>195332.056882</td>\n",
       "      <td>0.133528</td>\n",
       "      <td>83010.130932</td>\n",
       "      <td>83288.346243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lookback:6 Layers:1                                        \\\n",
       "                          R2           MAE      MAPE           AIC   \n",
       "morocco             0.982164   8027.250595  0.022421  62334.885335   \n",
       "paraguay            0.950593    146.690288  0.025836  36392.150629   \n",
       "usa                 0.980308  38775.828662  0.024746  72532.593749   \n",
       "\n",
       "                       Lookback:6 Layers:2                          \\\n",
       "                   BIC                  R2           MAE      MAPE   \n",
       "morocco   62635.812101            0.982147   8240.161112  0.022307   \n",
       "paraguay  36670.365940            0.948501    155.398985  0.027083   \n",
       "usa       72810.809060            0.979747  39507.751625  0.025337   \n",
       "\n",
       "                                      ... Lookback:24 Layers:1                 \\\n",
       "                   AIC           BIC  ...                   R2            MAE   \n",
       "morocco   62504.517598  62805.444364  ...             0.987972    6546.634698   \n",
       "paraguay  36765.867929  37044.083241  ...             0.956036     143.616675   \n",
       "usa       72653.768559  72931.983871  ...            -1.156424  412890.634409   \n",
       "\n",
       "                                               Lookback:24 Layers:2  \\\n",
       "              MAPE           AIC           BIC                   R2   \n",
       "morocco   0.017972  61013.672001  61314.598766             0.982963   \n",
       "paraguay  0.025133  36254.932022  36533.147333             0.943414   \n",
       "usa       0.290683  87860.292892  88138.508204             0.523606   \n",
       "\n",
       "                                                               \n",
       "                    MAE      MAPE           AIC           BIC  \n",
       "morocco     7844.128786  0.021287  62185.347988  62486.274753  \n",
       "paraguay     155.666450  0.027250  36777.011405  37055.226717  \n",
       "usa       195332.056882  0.133528  83010.130932  83288.346243  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea30ed7",
   "metadata": {},
   "source": [
    "#### LSTM hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ab326aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot to get out aic values\n",
    "#df = pd.DataFrame({key: [item[1] for item in value] for key, value in data.items()}, columns=columns, index=index)\n",
    "columns = hyperparameter_tuning.keys()\n",
    "index = ['morocco', 'paraguay', 'usa']\n",
    "df_aic = pd.DataFrame({key: [item[-2] for item in value] for key, value in hyperparameter_tuning.items()}, columns=columns, index=index)\n",
    "#df = pd.DataFrame(hyperparameter_tuning, index=[i for i in datasets_electricity.keys()])\n",
    "\n",
    "df_aic.plot.bar(figsize=(10, 5))\n",
    "plt.title('AIC for different hyperparameters with LSTM')\n",
    "#plt.ylim(0, 0.1)\n",
    "plt.ylabel('AIC')\n",
    "plt.xlabel('Datasets')\n",
    "plt.xticks(rotation=0)\n",
    "#plt.legend(title='Hyperparameters', title_fontsize='13', fontsize='11')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "045a934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot to get out aic values\n",
    "#df = pd.DataFrame({key: [item[1] for item in value] for key, value in data.items()}, columns=columns, index=index)\n",
    "columns = hyperparameter_tuning.keys()\n",
    "index = ['morocco', 'paraguay', 'usa']\n",
    "df_aic = pd.DataFrame({key: [item[-3] for item in value] for key, value in hyperparameter_tuning.items()}, columns=columns, index=index)\n",
    "#df = pd.DataFrame(hyperparameter_tuning, index=[i for i in datasets_electricity.keys()])\n",
    "\n",
    "df_aic.plot.bar(figsize=(10, 5))\n",
    "plt.title('MAPE for different hyperparameters with LSTM')\n",
    "plt.ylim(0, 0.1)\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('Dataset')\n",
    "#plt.legend(title='Hyperparameters', title_fontsize='13', fontsize='11')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9f43125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tuning_file = pd.read_csv(\"hyperparameter_tuning_results.csv\", header=[0, 1])\n",
    "\n",
    "# The file might be saved with tuples as column headers for multi-index. Let's handle that:\n",
    "def eval_tuples(x):\n",
    "    try:\n",
    "        return eval(x) if isinstance(x, str) and x.startswith('(') else x\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "# If the headers were saved as strings that represent tuples, convert them back to actual tuples (if necessary)\n",
    "df_tuning_file.columns = pd.MultiIndex.from_tuples([eval_tuples(col) if isinstance(col, str) else col for col in df_tuning_file.columns])\n",
    "\n",
    "# Optionally, set the first column as the DataFrame index if it represents your dataset identifiers\n",
    "#df_tuning_file.set_index(df_tuning_file.columns[0], inplace=True)\n",
    "\n",
    "df_tuning_file.head()\n",
    "\n",
    "# Plot the aic values\n",
    "\n",
    "#df = pd.DataFrame({key: [item[1] for item in value] for key, value in data.items()}, columns=columns, index=index)\n",
    "#columns = df_tuning_file.keys()\n",
    "index = ['morocco', 'paraguay', 'usa']\n",
    "#df_aic = pd.DataFrame({key: [item[-3] for item in value] for key, value in hyperparameter_tuning.items()}, columns=columns, index=index)\n",
    "#df = pd.DataFrame(hyperparameter_tuning, index=[i for i in datasets_electricity.keys()])\n",
    "aic_df = df_tuning_file.xs('AIC', level=1, axis=1) \n",
    "aic_df.plot.bar(figsize=(10, 5))\n",
    "plt.title('AIC for different hyperparameters with LSTM')\n",
    "#plt.ylim(0, 0.1)\n",
    "plt.ylabel('AIC')\n",
    "plt.xlabel('Dataset')\n",
    "#plt.legend(title='Hyperparameters', title_fontsize='13', fontsize='11')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "07ddb69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Autocorrelation 24-steps predicting Consumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "morocco, MAE: 8456.68, MAPE: 0.023, R2: 0.981\n",
      "LSTM Model - AIC: 62624.59, BIC: 62789.25\n",
      "Time taken: 38.40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "paraguay, MAE: 147.36, MAPE: 0.026, R2: 0.951\n",
      "LSTM Model - AIC: 36373.74, BIC: 36515.69\n",
      "Time taken: 156.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "usa, MAE: 54222.99, MAPE: 0.036, R2: 0.963\n",
      "LSTM Model - AIC: 74657.39, BIC: 74799.34\n",
      "Time taken: 176.47 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Autocorrelation 24-steps predicting Consumption\")\n",
    "autocorrelation_24_step = [] # list to store the MAPE results of each dataset\n",
    "for dataset_name in datasets_electricity:\n",
    "    start_time = time.time()\n",
    "    data = add_lagged_timesteps(datasets[dataset_name], lag_periods=[i for i in range(1, 25)], lagged_feature='Consumption').dropna().reset_index(drop=True)\n",
    "    r2, mae, mape, aic_value, bic_value = lstm_fitting_and_evaluation(data.drop(columns=['DateTime', 'Consumption', 'Temperature']), data['Consumption'], dataset_name, model_file_identifier=\"autocorrelation24_fully_trained\")\n",
    "    autocorrelation_24_step.append(aic_value)q\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedb910",
   "metadata": {},
   "source": [
    "#### Autocorrelation vs. temperature features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "74d0e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lagged temperature + time encodinggs predicting Consumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "morocco, MAE: 10539.67, MAPE: 0.028, R2: 0.974\n",
      "LSTM Model - AIC: 64207.42, BIC: 64814.95\n",
      "Time taken: 45.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "paraguay, MAE: 163.09, MAPE: 0.029, R2: 0.941\n",
      "LSTM Model - AIC: 37186.73, BIC: 37771.55\n",
      "Time taken: 196.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mariuslerstein/miniconda3/envs/master/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "usa, MAE: 32812.50, MAPE: 0.021, R2: 0.985\n",
      "LSTM Model - AIC: 71558.51, BIC: 72143.33\n",
      "Time taken: 215.00 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n Autocorrelation 48-steps predicting Consumption\")\n",
    "autocorrelation_48_step = [] # list to store the MAPE results of each dataset\n",
    "for dataset_name in datasets:\n",
    "    start_time = time.time()\n",
    "    data = add_lagged_timesteps(datasets[dataset_name], lag_periods=[i for i in range(1, 49)], lagged_feature='Consumption').dropna().reset_index(drop=True)\n",
    "    r2, mae, mape, aic_value, bic_value = lstm_fitting_and_evaluation(data.drop(columns=['DateTime', 'Consumption', 'Temperature']), data['Consumption'], dataset_name, model_file_identifier=\"no_weather\")\n",
    "    autocorrelation_48_step.append(aic_value)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\n Lagged temperature + time encodinggs predicting Consumption\")\n",
    "lagged_temp_plus_time = [] # list to store the AIC results of each dataset\n",
    "for dataset_name in datasets:\n",
    "    start_time = time.time()\n",
    "    data = add_time_features(datasets[dataset_name])\n",
    "    data = add_lagged_timesteps(data, lag_periods=[i for i in range(1, 49)], lagged_feature='Consumption')\n",
    "    data = add_lagged_timesteps(data, lag_periods=[i for i in range(1, 49)], lagged_feature='Temperature').dropna().reset_index(drop=True)\n",
    "    r2, mae, mape, aic_value, bic_value = lstm_fitting_and_evaluation(data.drop(columns=['DateTime', 'Consumption', 'Temperature']), data['Consumption'], dataset_name, model_file_identifier=\"weather\")\n",
    "    lagged_temp_plus_time.append(aic_value)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6ecd3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a df to plot the difference between 24-step and 48 step autoreg, with temp\n",
    "df_24_48_temp = pd.DataFrame({\n",
    "                    '24-steps': autocorrelation_24_step,\n",
    "                    '48-steps': autocorrelation_48_step,\n",
    "                    'Lagged temperature + time encodinggs': lagged_temp_plus_time,\n",
    "                    },\n",
    "                    index=[i for i in datasets.keys()])\n",
    "\n",
    "df_24_48_temp.plot.bar(figsize=(10, 5))\n",
    "#plt.ylim(30000, 80000)\n",
    "plt.title('AIC for weather features with LSTM')\n",
    "plt.ylabel('AIC')\n",
    "plt.xlabel('Dataset')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3c197ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use seaborn to plot histogram of the results of the different datasets against each other\n",
    "#df = pd.DataFrame({'48-steps': autocorrelation_48_step,\n",
    "#                    'Lagged temperature + time encodinggs': lagged_temp_plus_time,\n",
    "#                    },\n",
    "#                    index=[i for i in datasets.keys()])\n",
    "df.plot.bar(figsize=(10, 5))\n",
    "#plt.ylim(0, 0.05)\n",
    "plt.title('AIC for weather features with LSTM')\n",
    "plt.ylabel('AIC')\n",
    "plt.xlabel('Dataset')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5e19d",
   "metadata": {},
   "source": [
    "#### LSTM different features\n",
    "* baseline with the 24 or 48 step autoregression\n",
    "* conditional volatility?\n",
    "* moving mean feature\n",
    "* granger causality feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_lstm_predictions(x, i):\n",
    "        data = scaled_X_test[i - lookback:i+1]\n",
    "        generator = TimeseriesGenerator(data, scaled_y_test[:len(data.reshape(7, -1))], length=n_steps, batch_size=batch)\n",
    "        predictions = model.predict(generator)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    i = 100\n",
    "    print(model.predict(generator_test)[i-6:i-5])\n",
    "    print(scaled_X_test[i - lookback:i+1].shape)\n",
    "    print(wrapped_lstm_predictions(scaled_X_test, i))\n",
    "    \n",
    "    explainer = LimeTabularExplainer(\n",
    "        scaled_X_train,\n",
    "        feature_names=features.columns,\n",
    "        class_names=['Consumption'],\n",
    "        discretize_continuous=True,\n",
    "        random_state=0,\n",
    "        verbose=True, mode='regression'\n",
    "    )\n",
    "    \n",
    "    instance_index = 10  # Choose an index from the test set\n",
    "    instance = scaled_X_test[instance_index]\n",
    "    exp = explainer.explain_instance(instance, lambda x: wrapped_lstm_predictions(x, i), num_features=5)\n",
    "    print(f'Instance {i}:')\n",
    "    exp.show_in_notebook(show_table=True)\n",
    "\n",
    "    return r2, mae, mape\n",
    "\n",
    "print(\"\\n Autocorrelation 48-steps predicting Consumption\")\n",
    "autocorrelation_48_step = [] # list to store the (R2, MAE, MAPE) results of each dataset\n",
    "for dataset_name in datasets:\n",
    "    data = add_lagged_timesteps(datasets[dataset_name], lag_periods=[i for i in range(1, 49)], lagged_feature='Consumption').dropna().reset_index(drop=True)\n",
    "    mape = lstm_fitting_and_evaluation(data.drop(columns=['DateTime', 'Consumption', 'Temperature']), data['Consumption'], dataset_name, model_file_identifier=\"autocorrelation48_fully_trained\")\n",
    "    autocorrelation_48_step.append(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "88986a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 11 µs, total: 19 µs\n",
      "Wall time: 51 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#data = morocco.dropna().reset_index(drop=True)\n",
    "#lookback=48 # 2 days\n",
    "#n_layers=2\n",
    "#model_file_identifier = str(lookback) + '_' + str(n_layers)\n",
    "\n",
    "#mape = fitting_and_eval(data.drop(columns=['Consumption', 'Temperature']), data['Consumption'], 'morocco', model_file_identifier=model_file_identifier, lookback=lookback, n_layers=n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae07de5",
   "metadata": {},
   "source": [
    "### PyTorch implementation\n",
    "If you prefer not to use TensorFlow for building an LSTM model, another popular choice is PyTorch, a flexible deep learning framework that allows more explicit control over the model architecture and data flow. Here is a basic example of how to implement an LSTM for time series forecasting in PyTorch.\n",
    "\n",
    "In PyTorch, you define your model as a class that extends nn.Module. Below is a simple example.\n",
    "\n",
    "Your data should be formatted appropriately for PyTorch, typically as torch.Tensor objects. The input should be of shape (batch size, sequence length, number of features), and the labels should be of a compatible shape, depending on your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97c99fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3827d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acce208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373919b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out[:, -1, :] just means we are taking the last LSTM output for each sequence\n",
    "out = self.linear(out[:, -1, :]) \n",
    "return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "input_dim = 1  # number of features\n",
    "hidden_dim = 50\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=output_dim)\n",
    "\n",
    "# Mean Squared Error Loss\n",
    "criterion = torch.nn.MSELoss()   \n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2cd8a2",
   "metadata": {},
   "source": [
    "Training the model involves running the forward pass, calculating the loss, performing backpropagation, and updating the model parameters.\n",
    "\n",
    "In this code, X_train and y_train should be your training data and labels, respectively, formatted as PyTorch tensors. Ensure that the shapes of your data match the expectations of the model (X_train should have three dimensions: batch, sequence, features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96969026",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients w.r.t. parameters\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()  # Getting gradients w.r.t. parameters\n",
    "    optimizer.step()  # Updating parameters\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173875bb",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "After training, you can use the model to predict on new data. Ensure you format this data similarly to the training data before making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6723a",
   "metadata": {},
   "source": [
    "Here, X_test should be your test dataset, prepared in the same way as your training dataset.\n",
    "\n",
    "This example provides a basic introduction to implementing an LSTM in PyTorch for time series forecasting. Depending on your specific problem, you might need to adjust the model architecture, data preprocessing, or training process for optimal results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
